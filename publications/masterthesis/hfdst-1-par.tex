\section{Parallelle algoritmes}

\subsubsection{Motivatie}

De ``Wet van Moore''\cite{4785860} stelt dat het aantal transistors verdubbelt elke achttien maanden. De klokfrequentie stagneert echter. \cite{nomoore} verklaart dit door te stellen de gemiddelde afstand van een geleider slechts met $1/\sqrt{2}$ afneemt, vermits het kloksignaal beperkt is tot de overdrachtssnelheid van een geleider, leidt men hieruit af dat de kloksnelheid niet evenredig verhoogt. Het gevolg van deze evolutie is dat complexe problemen enkel uitgerekend kunnen worden indien men voldoende rekentijd beschikbaar stelt.
\paragraph{}
Een reactie is de introductie van het ``\emph{parallel rekenen}'' ofwel ``\emph{parallel computing}''. Een probleem wordt opgelost door programma's die op verschillende processoren tegelijk te draaien en elk een deel van het probleem oplossen. Door berichten uit te wisselen tussen de verschillende processoren of door een gemeenschappelijk geheugen aan te bieden communiceren de programma's die op de verschillende processoren draaien met elkaar.\cite{books/bc/KumarGGK94}

\paragraph{}
Door met verschillende processoren te werken hoopt men de rekentijd drastisch naar beneden te kunnen halen. Dit is echter niet de enige motivatie: doorgaans verbruiken zogenaamde \emph{multi-core} processoren - processoren waarbij verschillende \emph{kernen} op dezelfde machine aanwezig zijn - ook minder energie. Dit komt bijvoorbeeld omdat andere hardware zoals het moederbord slechts \'e\'enmaal voorkomen in de configuratie. Men kan dus ook beogen de aanwezige hardware effici\"enter te gebruiken.\cite{energyEfficency}

\paragraph{}
Sommige problemen kunnen bovendien enkel opgelost worden met parallelle algoritmen: weersimulaties houden variabelen bij voor heel wat locaties op de aarde. Deze variabelen leiden tot het gebruiken van grote hoeveelheden geheugen, meestal kan men niet al de data in het geheugen van \'e\'en machine opslaan\cite{parallelLargeMemory}. Door elke machine een deel van de data te laten opslaan en manipuleren kan dit probleem worden opgelost.

\paragraph{}
Parallelle algoritmes worden ook ingeschakeld wanneer de data gevoelig is en niet zomaar kan worden uitgewisseld: indien bijvoorbeeld verschillende bedrijven een globale planning willen opstellen, maar geen details over de interne werking openbaar wensen te maken, kunnen parallelle algoritmes een oplossing bieden\cite{Gaspero_amultiagent}.

\subsubsection{Prestaties van parallelle algoritmen}

De prestaties van een parallel algoritme worden meestal gemeten op basis van \emph{speed-up}: de mate waarin we virtueel de kloksnelheid kunnen opdrijven. We defini\"eren eerst enkele concepten waarna we kort een taxonomie hieromtrent toelichten.

\begin{definition}[Wall time, Speed-up, Effici\"entie\cite{Alba2005book}]
We defini\"eren de \emph{wall time} $T$ als de tijd tussen de start van het algoritme en het moment waarop het algoritme stopt. De \emph{wall time} maakt abstractie van het aantal processoren. De \emph{speed-up} is de verhouding tussen de \emph{wall-time} bij \'e\'en processor $T_1$ en de \emph{wall-time} bij $p$ processoren $T_p$:
\begin{equation}
\funm{speed-up}{p}=\displaystyle\frac{T_1}{T_p}
\end{equation}
Indien de algoritmen stochastisch van aard zijn, wordt de verhoudingen tussen de gemiddelde \emph{wall-time} gebruikt.
Wanneer we de \emph{speed-up} delen door het aantal processoren $p$ spreken we over de \emph{effici\"entie}:
\begin{equation}
\funm{effici\"entie}{p}=\funm{speed-up}{p}/p
\end{equation}
\end{definition}

\paragraph{}
Men streeft ernaar dat de \emph{speed-up} in het geval van $p$ processoren gelijk is aan $p$. Dit fenomeen noemt men \emph{lineaire speed-up}. Het komt echter voor dat bij het uitvoeren van een algoritme op $p$ processoren, het algoritme minder snel werkt dan het geval met $1$ processor. Dan spreken we over \emph{negatieve speed-up}.

\paragraph{}
Indien men een voor een ineffici\"ent algoritme een parallel equivalent schrijft, stelt men vaak een lineaire speed-up vast. Dit komt omdat een na\"ief algoritme meestal geen relaties tussen de verschillende componenten in de invoer zal uitbuiten. De lineaire speed-up is bijgevolg eerder optimistisch. Een sterkere metriek is daarom de \emph{strong speed-up}. In dit geval wordt de snelste parallelle implementatie tegenover de sterkste sequenti\"ele implementatie geplaatst. Omdat algoritmes in een parallelle context meestal maar een beperkt deel van de data ter beschikking hebben, wordt het ontwikkelen van \emph{lineaire speed-up} bijgevolg complexer en in sommige gevallen zelfs onmogelijk.

\paragraph{}
In eerder uitzonderlijke omstandigheden stelt men effectief superlineaire versnellingen vast. Dit is te wijten aan het effici\"enter gebruik van de aanwezig hardware. Cache is hierbij een uitstekend voorbeeld: bij multi-core processoren hebben de verschillende ``\emph{kernen}'' ofwel ``\emph{cores}'' meestal een eigen segment aan cache. Sommige gegevens worden gebruikt door alle processoren, bijgevolg wordt deze data in de gemeenschappelijke cache opgeslagen. Een gevolg is dat er meer ruimte beschikbaar is in de aparte caches voor specifieke data. Men noemt het effect van superlineaire versnellingen dan ook meestal het ``\emph{cache-effect}''\cite{cacheEffect}.

\subsubsection{Beperkingen en oplossingen}

Het verhogen van de snelheid met behulp van parallelle algoritmen is meestal een feit. Het optekenen van lineaire speed-up is echter geen evidentie. Dit komt onder meer door de ``\emph{Wet van Amadahl}''\cite{Amdahl:1967:VSP:1465482.1465560}. De meeste algoritmes hebben een zekere nood aan het sequentieel uitvoeren van bepaalde instructies. De Wet van Amadahl stelt dat gegeven de fractie van het aantal verplicht sequenti\"ele instructies, er een plafond bestaat en dat men met een willekeurig aantal processoren altijd onder dit plafond zal blijven. De ``\emph{Wet van Gustafson}''\cite{Gustafson:1988:RAL:42411.42415} stelt dan weer dat wanneer we de probleemgrootte arbitrair kunnen opdrijven, programma's wel een \emph{lineaire speed-up} kunnen halen. Dit komt omdat in de meeste gevallen de fractie aan de nodige sequenti\"ele instructies verwaarloosbaar klein wordt. Vermits we vooral ge\"interesseerd in het parallelliseren van grote optimalisatieproblemen, behoort \emph{lineaire speed-up} misschien alsnog tot de mogelijkheden. Een belangrijke opmerking is dat beide theorie\"en geen rekening houden met de eventuele overhead die bij parallelle algoritmen komt kijken zoals bijvoorbeeld het doorsturen van data over een netwerk.

\subsection{De belangrijkste parallellisatie paradigma}

Meestal beschouwd men twee verschillende modellen met betrekking tot parallellisatie: \emph{Message Passing Interface (MPI)} en \emph{Tuple Space}. We geven hieronder een korte samenvatting.

\subsubsection{Message Passing Interface}

In het geval van \emph{MPI} beschouwen we een set \emph{agents}: processoren die onafhankelijk werken op een eigen stuk geheugen. Deze agenten interagerend door het uitwisselen van berichten over een netwerk. Dit hoeft niet te betekenen dat de agenten ook effectief draaien op verschillende machines: men kan op elke \emph{core} van een machine een onafhankelijke agent laten werken en vervolgens de boodschappen laten bezorgen met behulp van de faciliteiten die de meeste besturingssystemen aanbieden.

\paragraph{}
In het geval de \emph{agents} wel degelijk op verschillende machines draaien werken ze meestal volgens een bepaalde \emph{topologie}: een structuur die bepaalt welke machines met elkaar verbonden zijn. Een belangrijk aspect in \emph{MPI} is ``\emph{Group Communication}'': agenten die met een significant gedeelte van de andere agenten tegelijk communiceren. Voor elke topologie zijn er dan ook algoritmes uitgewerkt om het aantal berichten tot een minimum te beperken.

\subsubsection{Tuple Space}

Een \emph{Tuple Space} is een model waarbij agenten kennis hebben van een globale wereld: de \emph{Tuple Space}. Elke agent kan tuples toevoegen in de tuple space en een query op de ruimte uitvoeren. Door tuples toe te voegen die dan door andere agenten worden verwerkt ontstaat er een communicatieprincipe. Een \emph{tuple space} verschilt echter van een \emph{message passing interface} omdat men meer abstractie maakt van de bestemming van een boodschap.