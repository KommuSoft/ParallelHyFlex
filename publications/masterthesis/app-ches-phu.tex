\section{\emph{PHUNTER: Pearl Hunter} (\#4)}
\label{sss:phunter}
\subsection{Implementatie}
\emph{Pearl Hunter}\cite{chesc-phunter} is gebaseerd op de jacht op parels en zeedieren. Dit proces kan het best uitgelegd worden als herhaalde diversificatie. Dit doen men door in de eerste plaats de metaheuristieken op te delen in twee categorie\"en: \emph{dives} die overeenkomen met de \abls{} \abllhn{} en \emph{surface moves} die de andere \abhn{} omvat. Daarnaast deelt men \emph{dives} verder op in \emph{snorkling} en \emph{deep dives}. \emph{Snorkling} houdt in dat men een \abls{} algoritme met lage \emph{depth of search} uitvoert en stopt op het moment dat men een betere oplossing ontdekt. \emph{Deep dives} daarentegen zoeken met een hoge \emph{depth of search} en stoppen enkel wanneer er geen verbetering meer waargenomen wordt. \emph{PHUNTER} combineert \emph{surface moves} en \emph{dives} in zogenaamde \emph{move-dive} iteraties. Bij zo'n \emph{move-dive} vertrekt men van enkele initi\"ele oplossingen. Vervolgens past men \emph{surface moves} toe en laat men de populatie groeien. Nadien ordent men de oplossingen. Enkel op interessante oplossingen wordt \emph{snorkling} toegepast. De beloftevolle oplossingen die uit deze \emph{snorkling}-fase komen, worden dan gebruikt als basis voor een \emph{deep dive}. Een \emph{deep dive} bestaat uit een sequentie van verschillende \abls{} \abllhn{}. Omdat de volgorde waarin deze heuristieken worden toegepast een belangrijke rol kan spelen worden verschillende volgordes parallel ge\"evalueerd. Na het \'e\'enmalig toepassen van zo'n sequentie worden de sequenties vergeleken. Enkel de beste sequentie wordt dan nog herhaaldelijk toegepast. Een laatste aspect die uniek is aan \emph{PHunter} is \emph{surface learning}: men evalueert omgevingen op basis van het aantal \abls{} iteraties dat het kost in de \emph{snorkling}-fase om de oplossing te verbeteren. Afhankelijk van het aantal iteraties wordt een omgeving gecategoriseerd als \emph{shallow water}, \emph{sea trench} of \emph{buoy in the water}. Op basis van de omgeving wordt een strategie bepaald voor de \emph{surface moves} in de volgende iteratie. De vier mogelijke strategie\"en zijn: \emph{average calls}, \emph{crossover emphasized}, \emph{crossover only} en \emph{online pruning}. De strategie wordt gekozen op basis van een \emph{decision tree} die werd opgesteld door \emph{WEKA} voor een bepaalde testcase. Een laatste aspect is het \emph{mission restart} principe: indien voor een lange tijd geen betere oplossing wordt gevonden of de oplossingen in de populatie zijn door \emph{surface moves} te gelijklopend, begint men weer men een nieuwe initi\"ele oplossing.
\subsection{Kritiek}
\begin{itemize}
 \item \emph{Decision tree} lost het probleem met de parameters niet op: parameters zitten in de \emph{decision tree} (opgesteld op basis van een aantal testen op historische data).
\end{itemize}