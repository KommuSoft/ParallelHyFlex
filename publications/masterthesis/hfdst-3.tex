\chapter{\emph{ParHyFlex}: Parallel \emph{HyFlex}}
\label{hoofdstuk:3}

\chapterquote{A skilled transition team leader will set the general goals for a transition and then confer on the other team leaders working with him the power to implement those goals.}{Richard V. Allen}

Op basis van de analyse in hoofdstuk \ref{hoofdstuk:2}, werd een systeem genaamd \emph{ParHyFlex} ge\"implementeerd die het mogelijk maakt om hyperheuristieken te implementeren in een parallelle context. De broncode van dit systeem is te vinden onder \url{https://www.github.com/KommuSoft/ParallelHyFlex??} en wordt nog verder actief ontwikkeld. Daar het beschrijven van parallelle algoritmes complex is, geven we eerst een algemeen overzicht. Daarna bespreken we welke probleemafhankelijke componenten we hebben toegevoegd om dit systeem beter te doen werken. Vervolgens beschrijven we de principes achter het parallel uitvoeren van de hyperheuristieken. We eindigen met een bondig overzicht en bespreken welke inzichten uit het vorige hoofdstuk relevant waren voor de implementatie van dit systeem.

\section{Systeem}

\paragraph{}
Zoals al eerder aangehaald maakt een hyperheuristiek een keuze uit verschillende transitie-functies. Deze transitiefuncties kunnen parallel ge\"implementeerd worden. Zo kunnen we bijvoorbeeld \emph{Local Search} heuristieken over verschillende processoren verdelen. Een nadeel van deze %TODO

\paragraph{}
Zowel \emph{HyFlex} als \emph{ParHyFlex} maken een duidelijk onderscheid tussen enerzijds het probleemafhankelijke gedeelte (de kennis die een de gebruiker zelf dient te injecteren om het systeem te laten werken) en het probleemonafhankelijke gedeelte (de strategie die bepaalt welke heuristieken we uitvoeren).

\subsection{Probleemafhankelijk gedeelte}

We werken echter in een parallelle context. Daarom is het interessant dat het probleemafhankelijke gedeelte meer functionaliteiten ter beschikking stelt die uitgebuit kunnen worden door het bovenliggende systeem. Concreet denken we hierbij aan vier zaken: \emph{afstandmetrieken}, \emph{ervaring-generatoren}, \emph{zoekruimte beperkers} en \emph{multi-objectieven}

\subsubsection{Afstandmetrieken}
\abhf{} laat problemen een functie aanbieden die twee oplossingen met elkaar kan vergelijken. Deze functie kunnen we theoretisch omvormen tot een afstandsmetriek (we stellen de afstand tussen twee dezelfde oplossingen gelijk aan 0, en tussen twee verschillende aan een arbitraire constante groter dan 0). Deze metriek levert echter weinig informatie op. In een sequenti\"ele context gebruikt men soms het aantal mutaties die tussen een oplossing en \'e\'en van zijn voorouders om de afstand af te schatten. Dit is natuurlijk slechts een benadering. In het geval van parallelle uitvoer zullen we bovendien meestal niet over deze informatie beschikken. Daarom is het nuttig om de afstand tussen twee oplossingen te kunnen inschatten. In het geval de afstand geen triviaal gegeven is, kan men verschillende afstandsmetrieken defini\"eren en beslist de bovenliggende hyperheuristiek over de waarde van de metrieken. Een afstandmetriek is dus gedefinieerd als:
 \begin{equation}
  \delta_i:\SolSet^2\rightarrow\RealSet^+
 \end{equation}
 
\subsubsection{Ervaring-generatoren}
Elk proces draait een eigen hyperheuristiek en komt een sequentie heuristieken tegen. Uitwisselen van de sequentie kan potentieel een voordeel opleveren omdat de hyperheuristieken met meer kennis van zaken kunnen beslissen. Het doorsturen van alle heuristieken is doorgaans niet mogelijk omdat dit een te grote druk op het netwerk zet en bovendien de overige processoren te veel rekenkracht zouden investeren in het analyseren van de ontvangen oplossingen. Door het uitwisselen van ervaring, een compacte voorstelling van beschouwde oplossingen, zouden we dit probleem kunnen oplossen.

\subsubsection{Zoekruimte-beperkers}
Wanneer processoren oplossingen met elkaar uitwisselen lopen we de kans dat de verschillende processoren op termijn vergelijkbare populaties onderhouden. Dit laatste is nuttig wanneer sterke oplossingen in de buurt liggen van de oplossingen in de populatie. Indien de populaties echter rond eenzelfde lokaal optimum liggen, is dit nefast. In dat geval proberen alle processoren het lokale optimum te zoeken in een eenzelfde gebied, en wordt migratie naar mogelijk betere oplossingen in een ander gebied minder evident. Het introduceren van een component die diversificatie afdwingt kan helpen te voorkomen dat we op ijle populaties stuiten.

\subsubsection{Multi-objectieven}
Alle processoren proberen hetzelfde optimalisatieprobleem op te lossen. Door extra objectieven te introduceren, kunnen we echter een meer divers zoekproces aanbieden. Deze extra objectieven zijn eerder virtueel en dienen meer als een \emph{tie-breaker} in bijvoorbeeld gevallen waarbij twee oplossingen dezelfde fitness-waarde hebben.

\subsubsection{Afdwingbare beperkingen als probleemonafhankelijke ervaring}

Een probleem bij het genereren van \emph{ervaring} en het beperken van de \emph{zoekruimte} is dat dit op een probleemonafhankelijke manier dient te gebeuren: de bovenliggende hyperheuristiek heeft geen details over de structuur van de configuraties en kan bijgevolg niet zelf de zoekruimte beperken of conclusies genereren. We kunnen ervaring voorstellen als een object waar de hyperheuristiek de specificaties niet van kent, maar in dat geval moet ervaring wel enkele algemene functionaliteiten kunnen aanbieden die nuttig zijn. Om dit probleem op te lossen voeren we het concept van een \emph{afdwingbare beperking} in.

\begin{definition}[Afdwingbare beperking]
Een \emph{afdwingbare beperking} is een 3-tuple: $\tupl{c,c^+,c^-}$. $c:\SolSet\rightarrow\BoolSet$ is hierbij een functie die controleert of een gegeven oplossing aan een bepaalde voorwaarde voldoet. $c^+:\SolSet\rightarrow\SolSet$ is een functie die een gegeven oplossing minimaal kan aanpassen zodat deze aan de voorwaarde voldoet. $c^-:\SolSet\rightarrow\SolSet$ past oplossingen minimaal aan zodat ze niet aan de voorwaarde voldoen. De set van alle afdwingbare beperkingen die we op een probleem kunnen toepassen noteren we als $\HypSet$.
\end{definition}

We kunnen een afdwingbare beperking als een vorm van ervaring zijn. In de loop der tijd kunnen we immers een hypothese ontwikkelen dat sterke oplossingen aan een bepaalde voorwaarde voldoen (bijvoorbeeld een variabele in het probleem krijgt een vaste waarde). We kunnen dan oplossingen aantrekken naar de hypothese door $c^+$ op willekeurige oplossingen toe te passen. Anderzijds kunnen we ook oplossingen afstoten van de hypothese met $c^-$. De bovenliggende hyperheuristiek dient echter niet op de hoogte te zijn welke voorwaarden een concrete afdwingbare beperking stelt, zolang deze maar de oplossingen kan manipuleren.

\paragraph{}
Afdwingbare beperkingen kunnen we eveneens gebruiken om de zoekruimtes te beperken. Elk proces kan immers een aantal afdwingbare beperkingen gebruiken om een bepaalde zoekruimte te beschouwen, terwijl het de afdwingbare beperkingen van de andere processoren gebruikt om uit de buurt van de andere zoekruimtes te blijven.

\paragraph{}
De hyperheuristieken zelf kunnen geen ervaring genereren, ze hebben immers geen weet van de structuur van een oplossing. Daarom zal het specifieke probleem dus een set functies defini\"eren die we \emph{hypothese-generatoren (hypogen)} noemen:
\begin{definition}
Een \emph{hypothese-generator (hypogen)} $g_i:\SolSet^{n_{g_i}}\rightarrow\HypSet$ is een functie die op basis van een set oplossingen een afdwingbare beperking kan genereren.	
\end{definition}

\subsection{Probleemonafhankelijk gedeelte}

Het probleemonafhankelijke gedeelte wordt ge\"implementeerd door de hyperheuristiek en kan dus los gezien worden van \emph{ParHyFlex}. Het probleemafhankelijke gedeelte biedt echter functionaliteiten aan waarvoor we ondersteuning kunnen bieden in het probleemonafhankelijke gedeelte.

\paragraph{}
In \emph{ParHyFlex} werden daarom de volgende componenten ge\"implementeerd: \emph{uitwisselen van oplossingen}, \emph{afbakenen van zoekruimtes}, \emph{genereren van ervaring} en \emph{onderhandelen over een nieuwe zoekruimte}. In de volgende subsubsecties zullen we deze taken verder bespreken.

\subsubsection{Uitwisselen van oplossingen}

Elke processor werkt met een eigen lokaal geheugen, maar reserveert ook plaats voor de geheugens van de andere processoren. Op het moment dat een nieuwe oplossing naar een lokale geheugencel geschreven wordt, zal op basis van een \emph{uitwisselingsstrategie} beslist worden met welke processoren deze oplossing zal worden gedeeld. De taak van het verzenden en ontvangen van een oplossing samen met een reeks uitwisselingsstrategie\"en wordt ondersteund door \emph{ParHyFlex}.

\subsubsection{Afbakenen van de zoekruimte}
 
De zoekruimte bewaken is ook een verantwoordelijkheid van \emph{ParHyFlex}. Hiervoor voorziet men twee sets van afdwingbare beperkingen: positieve en negatieve. Telkens wanneer er een nieuwe oplossing wordt gegenereerd\footnote{Of via uitwisseling in het geheugen wordt ingeladen.} zal \emph{ParHyFlex} alle beperkingen in de positieve set afdwingen en \'e\'en beperking uit de negatieve set. Het afdwingen gebeurt in een willekeurige volgorde. Dit komt omdat de beperkingen met elkaar kunnen interfereren: een eerste beperking kan een variabele op \'e\'en waarde zetten waarna de volgende beperkingen deze wijziging weer ongedaan maakt. Men kan dit probleem proberen op te lossen door alle permutaties uit te proberen in de hoop dat \'e\'en mutatie toch tot het correcte resultaat leidt. Dit is echter niet noodzakelijk zo, en bovendien vereist een dergelijke oplossing exponenti\"ele tijd. We nemen aan dat de beperkingen meestal minimaal met elkaar interfereren en dat een zoekruimte niet strikt moet worden bewaakt. De hierboven vernoemde strategie is niet verplicht. Men kan door een interface te implementeren een andere strategie hanteren.

\subsubsection{Genereren van Ervaring}
 
Telkens wanneer \'e\'en van de processoren een nieuwe oplossing voortbrengt, kan hij deze oplossing -- samen met andere oplossingen -- omzetten in een afdwingbare beperking. Een processor kan echter niet alle beperkingen blijven bewaren: het uitwisselen van ervaring dient snel te gebeuren, we dienen een voldoende grote zoekruimte te behouden en bovendien kunnen we net een beperking genereren die het zoeken de foute kant opstuurt. Daarom maken we gebruik van een \emph{ervaring-set}, een set van vaste grootte waar gegenereerde beperkingen in worden bewaard. De elementen in de set worden telkens ge\"evalueerd: telkens wanneer er een nieuwe oplossing wordt gegenereerd, zal de \emph{ervaring-set} kijken aan welke beperkingen de oplossing voldoet. Op basis van de fitness-waarde van de oplossingen kunnen de beperkingen dan ge\"evalueerd worden. Door de lijst van fitness-waardes op te delen in waardes waarbij de beperking wordt gerespecteerd en waardes waarbij dat niet het geval is, ontstaan twee sets aan punten. Met een online algoritme\cite[p. 232]{citeulike:175026} berekenen we voor beide sets het gemiddelde en de variantie. Door de evaluaties van beide sets als onafhankelijke normale verdelingen te beschouwen, kunnen we de kans uitrekenen dat een fitness-waarde van een oplossing die aan de voorwaarde voldoet kleiner is dan de oplossing die niet aan de voorwaarde voldoet. Naarmate de kans groter wordt maken we de assumptie dat de beperking beter is. Omdat de gegenereerde beperkingen ook fout kunnen zijn, dienen we de set regelmatig van nieuwe hypotheses te voorzien, dit proces heet \emph{amnesie}. \emph{Amnesie} wordt op geregelde tijdstippen toegepast: oude hypotheses worden uit de set gehaald op plaats te maken voor nieuwe hypotheses. We wensen dat sterke hypothese meer kans maken om te overleven maar wel de kans lopen om te verdwijnen. Daarom rangschikken we de beperkingen op basis van hun evaluatie. De kans dat de hypothese vervolgens uit de set wordt gehaald berekenen we vervolgens op basis van de Benford-verdeling\cite{citeulike:748130}.

\subsubsection{Onderhandelen over een nieuwe zoekruimte}

Elke processor houdt een \emph{ervaring-set} bij. Het is de bedoeling dat deze ervaring wordt gebruikt om een nieuwe zoekruimte af te dwingen. Bovendien kan ervaring uitgewisseld worden met andere processoren zodat deze later ook hun zoekruimtes aanpassen. Tegelijk willen we voorkomen dat de zoekruimtes te homogeen worden en dus potentieel sterke oplossingen genegeerd worden. Dit zijn de taken van de \emph{onderhandelaar}. De \emph{onderhandelaar} is een component die af en toe geactiveerd wordt. Een deel van de afdwingbare beperkingen worden uit de \emph{ervaring-set} gehaald om opgenomen te worden in het positieve component van de \emph{zoekruimte}. Deze beperkingen worden via groepscommunicatie doorgestuurd naar de andere processoren. Een deel van de ontvangen beperkingen komen terecht in de \emph{ervaring-set} een andere deel vormt de basis van het negatieve gedeelte van de \emph{zoekruimte}. Omdat een deel van de afdwingbare beperkingen vanaf dan in de \emph{ervaring-set} van de andere processoren wordt ge\"evalueerd (met een andere zoekruimte), is men in staat om zo'n beperking op een objectievere manier te evalueren\footnote{Sommige afdwingbare beperkingen leiden immers enkel tot sterke resultaten in een bepaalde \emph{zoekruimte}.}.

\subsubsection{Invloed van hoofdstuk \ref{hoofdstuk:2}}

\subsection{Overzicht}

\importtikz[1.4]{parhyflexstructure}{parhyflexstructure}{Structuur van \emph{ParHyFlex}.}
Op \imgref{parhyflexstructure} geven we schematisch de structuur van \emph{ParHyFlex} weer.	De componenten die gemarkeerd worden met een asterisk, zijn component die niet aanwezig zijn in \emph{HyFlex}. Het grijze blok stelt de kern van het \emph{ParHyFlex} systeem voor.%TODO

\paragraph{}
Een deel van de geheugencellen is gemarkeerd met een schuine streep. Deze geheugencellen stellen vreemd geheugen voor waarvan er lokaal een kopie wordt bijgehouden. De geheugencellen kunnen uitgelezen worden, maar er kan geen oplossing naar geschreven worden.

\paragraph{}
\importtikz[1.4]{parhyflexwerking}{parhyflexwerking}{Schematische voorstelling van de kern van \emph{ParHyFlex}.}
Op \imgref{parhyflexwerking} beschrijven we kort het proces die een berekende of ontvangen oplossing doormaakt. Deze oplossing -- op de figuur $s_1^{(0)}$ -- wordt eerst aangepast door de zoekruimte: alle positieve hypotheses en \'e\'en negatieve hypothese worden toegepast op de oplossing en wordt aangepast tot $s_1^{(E)}$ die binnen de zoekruimte valt. De fitness-waarde wordt berekend en de evaluaties van de reeds aanwezige hypotheses in de ervaring-set worden aangepast (de data wordt voor elke hypothese opgenomen in \'e\'en van de twee normale verdelingen). Verder wordt met behulp van \'e\'en van de hypothesegeneratoren  een hypothese gegenereerd die met een bepaalde kans opgenomen wordt in de ervaring-set. De oplossing wordt vervolgens in het geheugen opgenomen en eventueel doorgestuurd naar andere processoren.

\paragraph{}
Op geregelde tijdstippen treed er amnesie op in de \emph{ervaring-set}: een deel van de hypothese worden uit de set verwijdert. Dit gebeurt op basis van de twee normale verdelingen per hypothese. Op die manier kan men zich ontdoen van foute hypothese, en maakt men ruimte voor nieuwe hypotheses.

\paragraph{}
Op vaste tijdsintervallen zal de \emph{onderhandelaar} een deel van de hypotheses uit de \emph{ervaring-set} halen. Een deel van deze hypotheses vormen de nieuwe positieve set van de \emph{zoekruimte}. De overige worden doorgestuurd in de \emph{ervaring-set} van de andere processoren ge\"injecteerd. Een deel van de doorgestuurde hypotheses vormt ook een basis van de negatieve set van de \emph{zoekruimte}.

\section{\emph{ParAdapHH}}

Naast het ontwikkelen van een systeem om hyperheuristieken op verschillende processoren te kunnen laten werken, vereist het testen van het systeem sowieso dat we een concrete hyperheuristiek ontwikkelen. Een logische keuze is om \emph{AdapHH}, de hyperheuristiek voorgesteld door Mustafa M\i{}s\i{}r te implementeren. We geven eerst een motivatie voor deze hyperheuristiek. Daarna bespreken we in meer detail de werking van de hyperheuristiek samen met de wijzigingen om het systeem op verschillende processoren te laten werken.

\subsection{Motiviatie}

\subsection{Werking}

In het vorige hoofdstuk hebben we de werking van \emph{AdapHH} al op hoog niveau beschouwd. In deze subsectie zullen we de werking in meer detail bespreken en de wijzigingen in de context van een parallel systeem bespreken.

\paragraph{}
\emph{AdapHH} is een hyperheuristiek die de gegeven tijd opdeelt in fases. Het maakt gebruik van twee mechanismes die een effici\"ente sequentie genereren: \emph{Adaptive Dynamic Heuristic Set (ADHS)} en \emph{Relay Hybridisation (RH)}. \emph{ADHS} onderhoudt een tabu-set van heuristieken die in het verleden tot sterke resultaten hebben geleid. Heuristieken die niet aan dit criterium voldoen, worden enkele fases uit de set gehaald en daarna opnieuw ge\"introduceerd. Het \emph{RH} component werkt met een \emph{learning automaton}\cite{learningAutomaton} en voert twee heuristieken na elkaar uit. De twee mechanismes worden door elkaar gebruikt. Telkens wanneer \'e\'en van de twee mechanismen een nieuwe oplossing berekend, zal het \emph{Adaptive Iteration Limited List-based Threshold Accepting (AILLA)}-component beslissen of de nieuwe oplossing als actieve oplossing wordt aanvaard.

\subsubsection{ADHS}
\emph{AdapHH} probeert een set van sterke heuristieken te onderhouden. Hiervoor werkt het algoritme in fases. Een heuristiek wordt beoordeelt volgens de prestaties die het sinds de start heeft afgelegd, maar de prestaties in de laatste fase wegen zwaarder door in het besluit of een hyperheuristiek in de set blijft of enkele fases niet meer wordt gebruikt. Om heuristieken te evalueren wordt van volgende metriek gebruik gemaakt:
\begin{align*}
\funm{eval}{h_i}\isdefinedas{}&w_1\cdot\fbrk{\brak{1+\fun{C_{f,\smbox{best}}}{h_i}}\cdot t_{\smbox{rem.}}/t_{f,\smbox{spent}}}\cdot b+\\
&w_2\cdot\fbrk{\fun{f_{f,\smbox{imp}}}{h_i}/t_{f,\smbox{spent}}}-w_3\cdot\fbrk{\fun{f_{f,\smbox{wrs}}}{h_i}/t_{f,\smbox{spent}}}+\\
&w_4\cdot\fbrk{\fun{f_{\smbox{imp}}}{h_i}/t_{\smbox{spent}}}-w_5\cdot\fbrk{\fun{f_{\smbox{wrs}}}{h_i}/t_{\smbox{spent}}}\\\\
b\isdefinedas{}&\krdelta{\exists h_j:\fun{C_{f,\smbox{best}}}{h_j}>0}
\end{align*}
Met $C_{\smbox{best}}$ het aantal globaal betere oplossingen die de heuristiek heeft gevonden, $f_{\smbox{imp}}$ en $f_{\smbox{wrs}}$ de totale verbetering en verslechtering die de heuristiek veroorzaakt heeft. $t_{\smbox{spent}}$ houdt de totale rekentijd van een specifieke heuristiek bij. Indien er een subscript $f$ bij de metrieken wordt geplaatst, gaat het om de metriek in de laatste fase.

\paragraph{}
Een logische stap naar parallellisatie is het doorsturen van van de componenten van de metriek en vervolgens een uitspraak doen op basis van meer gegevens. Dit wordt echter bemoeilijkt door het feit dat de fases niet synchroon verlopen en dit bovendien de semantiek van een fase onderuit zou halen: uitspraken doen over hoe goed de heuristieken werken op een set gelijkaardige populaties. De metriek bevat echter ook enkele componenten die niet minder afhankelijk zijn van de laatste fase. Daarom introduceren we twee nieuwe termen die een uitspraak doen over het globale plaatje:
\begin{align*}
\funm{eval'}{h_i}\isdefinedas{}&w_1\cdot\fbrk{\brak{1+\fun{C_{f,\smbox{best}}}{h_i}}\cdot t_{\smbox{rem.}}/t_{f,\smbox{spent}}}\cdot b+\\
&w_2\cdot\fbrk{\fun{f_{f,\smbox{imp}}}{h_i}/t_{f,\smbox{spent}}}-w_3\cdot\fbrk{\fun{f_{f,\smbox{wrs}}}{h_i}/t_{f,\smbox{spent}}}+\\
&w_4\cdot\fbrk{\fun{f_{\smbox{imp}}}{h_i}/t_{\smbox{spent}}}-w_5\cdot\fbrk{\fun{f_{\smbox{wrs}}}{h_i}/t_{\smbox{spent}}}\\
&w_6\cdot\fbrk{\fun{f_{g,\smbox{imp}}}{h_i}/p\cdot t_{g,\smbox{spent}}}-w_7\cdot\fbrk{\fun{f_{g,\smbox{wrs}}}{h_i}/p\cdot t_{g,\smbox{spent}}}
\end{align*}
Waarbij het subscript $g$ betekent dat het gaat over de som van de gegevens van alle processoren. De gegevens worden op geregelde tijdstippen doorgestuurd om minder bandbreedte en rekenwerk aan boekhoudkundige taken toe te wijzen.

\paragraph{}
Op basis van de evaluatie worden de heuristieken gerangschikt met een kwaliteitsindex. De heuristieken met een kwaliteitsindex die onder het gemiddelde ligt, worden uit voor een periode van $\sqrt{2\cdot n}$ uit de set verwijdert (met $n$ het aantal heuristieken). Heuristieken die tijdelijk niet meer tot de set behoren worden hebben allemaal een kwaliteitsindex van $1$. Indien een heuristiek de fase nadat deze terug in de set werd ge\"introduceerd opnieuw wordt verwijdert, neemt het aantal fases toe. Indien het aantal tabu-fases verdubbelt is, wordt de heuristiek definitief verwijdert.

\paragraph{}


\subsubsection{RH}
Naast \emph{ADHS} is \emph{RH} ook een mechanisme om heuristieken te selecteren. Per iteratie in de fase zal met stijgende kans dit mechanisme geactiveerd worden. Op basis van een \emph{learning automaton} wordt een heuristiek gesecteerd die wordt toegepast op de actieve oplossing. Elke heuristiek onderhoud een lijst met heuristieken die effectief bleken als tweede transitiefunctie. Met een bepaalde kans wordt een heuristiek uit deze lijst geselecteerd. In het andere geval wordt er een toevallige heuristiek geselecteerd. Die tweede heuristiek wordt dan toegepast op het resultaat van de eerste heuristiek. De \emph{learning automaton} gebruik een \emph{lineair reward-interaction update schema} waardoor combinaties die globaal betere oplossingen vinden meer kans maken in de volgende iteraties.

\paragraph{}
In het geval van een \emph{learning automaton}, is \emph{mimetism} een populaire oplossing: het nabootsen van de toestanden van de andere processen. Na elke fases stuurt het proces de verschillen in de kansvector door naar de andere processoren. Deze verschillen worden gedeeltelijk doorgerekend. Door de wijzigingen slechts gedeeltelijk door te rekenen, hopen we voorkomen dat de kansvectoren uit de hand kunnen lopen.

\subsubsection{AILLA}
Nadat \'e\'en van de twee mechanismes (\emph{ADHS} of \emph{RH}) een nieuwe oplossing heeft gegenereerd, zal de heuristiek beslissen of deze oplossing de nieuwe actieve oplossing wordt. Dit is de verantwoordelijkheid van \emph{AILLA}. \emph{AILLA} beschouwd twee verschillende gevallen:
\begin{enumerate}
 \item In het geval de gegenereerde oplossing beter is dan de originele oplossing, wordt deze altijd geaccepteerd.
 \item In het andere geval wordt de oplossing alleen geaccepteerd wanneer de fitness-waarde beter is dan de fitness-waarde een historisch beste oplossing. Hiervoor onderhoud \emph{AILLA} een lijst van de laatste globaal beste oplossingen. Het aantal maal tot nu toe na elkaar het accepteren van een oplossing werd geweigerd bepaald hoe diep er terug in het verleden wordt gekeken om een oplossing alsnog te accepteren.
\end{enumerate}

\importtikz[1.4]{ailla}{ailla}{Werkingsprincipe van \emph{AILLA}.}

\imgref{ailla} illustreert dit principe. Op de figuur worden de verschillende mogelijke configuraties voorgesteld door de horizontale as. De verticale as geeft de fitness-waarde van de overeenkomstige configuratie weer. Wanneer we reeds enkele oplossingen hebben overlopen, hebben we enkele fitness-waardes. Deze waardes worden door de dunne grijze horizontale lijnen voorgesteld. Een oplossing zal hier geaccepteerd worden wanneer deze zich onder de tweede horizontale lijn zit: het is immers al de tweede maal op rij dat we proberen een nieuwe oplossing te accepteren. %TODO: figuur aanpassen

\paragraph{}
We kunnen dit systeem verreiken door in de lijst van beste fitness-waardes ook de resultaten van andere processoren op te nemen. Hierdoor streven we naar sterkere stijgingen. Bovendien verwachten we dat dit op termijn gehaald zal worden: er worden immers ook oplossingen uitgewisseld waar andere processoren dan gebruik van kunnen maken. Door echter te strenge grenzen op te leggen kan een processor veel iteraties nodig hebben alvorens een nieuwe oplossing zal geaccepteerd worden. Daarom werd dit systeem aangepast zodat hooguit de helft van de lijst bestaat uit vreemde fitness-waardes.

\subsubsection{Andere componenten}

\paragraph{Kruisingsheuristieken}
In het geval \emph{AdapHH} een kruisingsoperator selecteert, dient men een andere oplossing te selecteren. In dat geval kiest \emph{AdapHH} een historisch beste oplossing. Dit hoeven niet noodzakelijk de laatste beste oplossingen te zijn. Telkens wanneer er immers een nieuwe beste oplossing wordt gevonden, wordt dit op een willekeurige plaats in een lijst met vaste grootte gezet. We kunnen het uitwisselingsmechanisme van \emph{ParHyFlex} uitbuiten: in plaats van uitsluitend te kiezen uit de lijst van lokale oplossingen, kunnen ook oplossingen die door een andere machine werden gegenereerd en doorgestuurd worden gebruikt.