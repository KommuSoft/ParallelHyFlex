\section{Conclusies}
Het trekken van algemene conclusies bij de hierboven beschreven systemen is complex: de meeste systemen omvatten verschillende componenten en daarom kunnen we nooit eenduidig besluiten of de superioriteit van \'e\'en \abhh{} tegenover de andere wel degelijk te wijten is aan een bepaald aspect van deze \abhh{}.

\subsection{Tabu lijsten versus probabiliteitsvectoren}
Toch kunnen we op z'n minst enkele hypotheses naar voren schuiven. Een eerste hypothese is dat bij de selectie van \abllhn{} een aanpak met behulp van \emph{Tabu Search} doorgaans superieur lijkt te zijn aan de selectie door middel van probabiliteitsvectoren. Een waarschijnlijke verklaring is dat de probabiliteitsvectoren meestal in een onstabiele situatie verzeilt kunnen raken waarin omdat een bepaalde heuristiek vaker wordt geselecteerd, er meer kans is om de probabiliteit verder te verhogen. Hierdoor komen we in een situatie waarin na verloop van tijd slechts een gedeelte van de \abllhn{} nog regelmatig wordt opgeroepen. Deze \abllhn{} kunnen na verloop van tijd \abieff{} gedrag vertonen (we denken hierbij bijvoorbeeld aan het idempotent gedrag van \abls{}), maar worden hiervoor niet bestraft (en zelfs beloond). \emph{Tabu Search} kunnen we zien als een probabiliteitsvector waarbij enkele componenten kansloos zijn en de actieve \abhn{} de kansen eerlijk verdelen. Een belangrijk aspect van \emph{Tabu Search} is echter het \emph{forgive-and-forget}-karakter: na een zekere tijd komt een \abh{} weer in de actieve set en krijgt deze opnieuw een eerlijke kans. In het geval van \emph{AdapHH} zien we dat dit bovendien niet hoeft te betekenen dat we alle opgedane ervaring weggooien: de metriek die bepaalt welke \abhn{} er de volgende fase tabu worden bevat immers eigenschappen die een uitspraak doen over de volledige periode dat het algoritme actief is. Men geeft echter wel een doorslaggevende rol aan de laatste fase waardoor een \abh{} de kans krijgt om zich in een fase wel degelijk te bewijzen.

\subsection{Normalisatie van fitness-waardes}
Een ander belangrijk aspect is het rekenen met de fitness-waarde van een zekere oplossing. Men stelt vast dat de fitness-waarde dikwijls volgens een exponenti\"ele functie daalt. Dit betekent dat we in het begin een grote vooruitgang mogen verwachten en naar het einde toe een veel minder sterke vooruitgang. Dit is logisch vermits het in het begin makkelijk is om tot een betere oplossing te komen dan de voorheen gevonden oplossing. Na verloop van tijd zitten we echter vast op lokale optima die in de meeste gevallen in kwaliteit weinig verschillen met het globale optimum.

\paragraph{}
Het is van belang dat we rekening houden met dit fenomeen. We zien bijvoorbeeld dat slecht presterende \abhhn{} meestal een lineair beloningssysteem gebruiken: \abhn{} worden beloond op basis van het absolute of relatieve verschil in fitness-waarde tussen de oorspronkelijke en nieuwe oplossing. Dit betekent echter dat de \abhn{} die eerste geselecteerd worden meestal bevoordeeld worden tegenover later geselecteerde oplossingen die het meestal met minder vooruitgang moeten stellen.

\paragraph{}
We zien dat de betere \abhhn{} dit probleem op verschillende manieren oplossen. \emph{AdapHH} hecht bijvoorbeeld maar weinig belang aan de verschil in fitness-waarde: de belangrijkste metriek is het aantal keer dat de metaheuristiek een nieuw globaal optimum levert. De frequentie waarmee dit laatste gebeurt neemt ook af, maar minder sterk. Hierdoor geeft men meer gelegenheid aan een \abh{} om zich te bewijzen. Normalisatie zien we ook in de \emph{move acceptance} component: we accepteren een nieuwe oplossing op basis van de fitness-waarde van de meest recente globale optima.

\subsection{Behoud van status quo en tijdmeting}
Een ander aspect is het behouden van status-quo. In de kritieken kwam vaak aan bod dat het algoritme geen rekening houdt met de idempotentie van de \abls{} \abhn{}. Dit laatste leidt tot het verlies van een aanzienlijke hoeveelheid rekenkracht. Dit komt gedeeltelijk door de karakteristieken van \abls{}: bij een \abls{} \abh{} beschouwen we immers een relatief grote zoekruimte, voor elke instantie moet daarenboven de fitness-waarde uitgerekend worden. Mutatie-operatoren leveren per definitie een andere oplossing af en bestede hier meestal een minimum aan tijd aan.

\paragraph{}
Betere \abhhn{} bestraffen dan ook \abhn{} die een oplossing voorstellen die equivalent is aan het origineel. \emph{VNS-TW} bijvoorbeeld bestraft bijvoorbeeld in 20\% van de gevallen de \abh{} die tot een equivalent resultaat komt. \emph{AdapHH} gaat zelfs een stapje verder en bestraft onder bepaalde voorwaarden de \abhn{} die in een fase niet tot een nieuw globaal optimum kwamen en een significante hoeveelheid tijd in beslag namen.

\subsection{Robuuste parameters tijdens het zoekproces}
Heel wat algoritmes bevatten veel parameters. Sommige systemen ontwikkelen leersystemen die deze parameters moeten zetten. Een probleem met deze aanpak is dat deze leersystemen op hun beurt weer parameters introduceren. Meestal is er geen enkele garantie is dat deze parameters robuuster zullen zijn. Bij de meeste systemen ontbreekt een duidelijke motivatie die leersystemen voor parameters rechtvaardigt.

\paragraph{}
De meest succesvolle oplossing voor het oplossen van dit probleem bestaat er dan ook uit verschillende leersystemen tegelijk te beschouwen. Indien \'e\'en van de systemen dan faalt om op een effici\"ente manier tot een goede oplossing te komen is er nog altijd de hoop dat de andere systemen daar wel in slagen. Dit concept is bijvoorbeeld duidelijk ge\"implementeerd in \emph{AdapHH} waar naast een systeem met ``\emph{Tabu Search}'' ook het ``\emph{Hybrid Relay}'' systeem gebruikt wordt.