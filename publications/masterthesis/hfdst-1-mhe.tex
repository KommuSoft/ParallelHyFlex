\section{Metaheuristieken}

Een familie van heuristieken probeert enkele gewenste eigenschappen bij een heuristiek te combineren. Deze familie van heuristieken noemt men \emph{metaheuristieken}\cite{journals/cor/Glover86}. We bespreken eerst de gewenste heuristieken waarna we een formele definitie voorstellen.

\subsection{Gewenste eigenschappen bij een heuristiek}

Meestal zijn we slechts ge\"interesseerd in het gebruik van een heuristiek wanneer hier enkele garanties tegenover staan. Zo kunnen sommige heuristieken garanderen dat de fitness-waarde van hun benaderende oplossing hoogstens het dubbele is van de fitness-waarde van het globale optimum. Voor veel praktische problemen is dit echter niet mogelijk vanwege de complexiteit van het probleem. Meestal is het ook interessant dat de heuristiek aanpasbaar is.

\paragraph{}
Voor de meeste toepassingen wensen we een oplossing die binnen een gegeven tijd wordt uitgerekend. Sommige heuristieken voorzien een parameter waarmee men kan aangeven binnen welke termijn men een benaderende oplossing wenst.

\paragraph{}
De meeste heuristieken worden ontwikkeld door het probleem met behulp van slechts \'e\'en strategie op te lossen. Deze strategie werkt meestal goed op een groot deel van de probleem instanties. Meestal bestaan er echter probleeminstanties waarop de gegeven strategie niet is afgesteld, wat leidt tot tegenvallende resultaten. Een sterke heuristiek probeert voor elke probleeminstantie een acceptabele oplossing te genereren.

\subsection{Formele definitie}

Metaheuristieken proberen de bovenstaande eigenschappen te combineren in een algemene oplossingsmethode. We geven eerst een formele definitie van een metaheuristiek waarna we relevante terminologie invoeren.

\begin{definition}[Metaheuristiek]
\deflab{metaheuristic}
Een \emph{metaheuristiek} is een algoritme die een oplossingsruimte $\SolSet\subseteq\accl{\sol|\forall \sol\in \ConfigSet:\fun{\hcfun}{\sol}}\subseteq\ConfigSet$ beschouwd met $\bestSol\in\SolSet$. Verder beschouwd het \'e\'en of meer \emph{overgangsfuncties} $h_i:\SolSet^{k_i}\times\RealSet^{l_i}\rightarrow\SolSet$. De re\"ele parameters zijn in deze context toevalsgetallen.\\
Een metaheuristiek zoekt een oplossing door \'e\'en of meerdere instanties $s_1,s_2,\ldots,s_j$ uit $\SolSet$ te genereren. Vervolgens wordt herhaaldelijk een aantal \emph{overgangsfuncties} toegepast op deze instanties. De resultaten van deze functietoepassingen worden als invoer bij een volgende iteratie gebruikt. Het algoritme stopt wanneer aan een bepaalde \emph{stopconditie} voldaan is (bijvoorbeeld: het algoritme draait een bepaalde tijd op de machine). Hierna wordt de oplossing met de beste fitness-waarde als uitvoer teruggegeven.
\end{definition}

Op basis van deze definitie kunnen we ook een algoritme op hoog niveau opstellen zoals beschreven in \algref{metaheuristicGeneral}.

\importalgo{metaheuristicgeneral}{Hoog niveau beschrijving van een metaheuristiek\cite{DBLP:journals/jc/ShonkwilerV94}.}{metaheuristicGeneral}

De aanwezigheid van toevalsgetallen is kenmerkend aan een metaheuristiek: typisch vereist elke overgangsfunctie \'e\'en of meer toevalsgetallen als invoer. Deze toevalsfactoren introduceren het concept van een \emph{omgeving} ofwel ``\emph{neighborhood}'' van een oplossing-set volgens een overgangsfunctie:

\begin{definition}[Omgeving van een oplossing-set volgens een overgangsfunctie\cite{Alba2005book}]
De \emph{omgeving} van een \emph{oplossing-set} volgens een \emph{overgangsfunctie} is de verzameling van alle oplossingen die we kunnen genereren door de overgangsfunctie toe te passen op deze oplossing-set, ongeacht de waarde van de toevalsfactoren. De omgeving van een functie $h_i$ kunnen we dus formeel uitdrukken als volgt:
\begin{equation}
\fun{\neighbr_{h_i}}{s_1,s_2,\ldots,s_{k_i}}=\accl{\fun{h_i}{s_1,s_2,\ldots,s_{k_i},\xi_1,\xi_2,\ldots,\xi_{l_i}}|\forall \xi_1,\xi_2\ldots \xi_{l_i}\in\RRR}
\end{equation}
\end{definition}

\subsubsection{Local Search}
Het concept van een omgeving is belangrijke omdat het meteen ook een populaire zoek\-strategie voor metaheuristieken introduceert: \emph{lokaal zoeken} ofwel ``\emph{local search (LS)}''. Deze zoekstrategie vertrekt van een gegeven oplossing en zoekt - volgens een bepaalde omgeving - alle oplossingen in de buurt af op zoek naar een betere oplossing. In het geval we zo'n oplossing vinden wordt deze oplossing de nieuwe oplossing en beginnen we vervolgens een zoektocht rond de nieuwe oplossing. Local Search komt voor in twee smaken: ``\emph{first-improvement}'' en ``\emph{best-improvement}''. In het geval van \emph{first-improvement} wordt de eerste oplossing die beter is dan de huidige oplossing de nieuwe actieve oplossing. In het geval van \emph{best-improvement} doorzoeken we de volledige omgeving en migreren we naar de beste oplossing in de omgeving.
\paragraph{}
Local Search is een krachtige optimalisatietechniek die doorgaans tot acceptabele resultaten kan leiden. Een probleem vormt echter het \emph{idempotente} karakter van local search: \'e\'enmaal we local search op een oplossing hebben toegepast heeft een tweede maal local search toepassen met dezelfde omgevings-definitie geen zin: we weten immers dat er in de omgeving geen betere oplossingen gevonden zullen worden want anders was het algoritme de vorige keer niet bij deze oplossing gestopt. Omwille van deze reden kan local search zelf geen volwaardige metaheuristiek worden genoemd\cite{lsAndMh}. We verwachten immers dat als we meer tijd investeren, we op termijn altijd tot betere resultaten $\xdot$ ofwel de echte oplossing $\xstar$ zullen komen. Local search vormt echter de basis voor een groot aantal metaheuristieken die doorgaans een mechanisme implementeren om uit een lokaal optimum te kunnen ontsnappen.

\subsection{De ``Zoo van de Metaheuristieken''}

\defref{metaheuristic} is vrij abstract. Daarom zullen we in deze sectie de belangrijkste families van metaheuristieken kort beschouwen. Referentiewerken die hier dieper op ingaan zijn \cite{Glover2003,gendreau2010handbook,blum2003metaheuristics,osman:1996}.

\subsubsection{Genetische Algoritmes}

\emph{Genetische algoritmen} ofwel ``\emph{Genetic Algorithms (GA)}'' zijn de eerste familie van metaheuristieken en werken op basis van een populatie: een set van oplossingen. Uit deze populatie worden twee of meer oplossingen geselecteerd, meestal op basis de fitness-waarde van deze oplossingen. Vervolgens past men een \emph{recombinatie} operator ofwel \emph{crossover} toe: een overgangsfunctie die de geselecteerde oplossingen omzet in een nieuwe oplossingen die bepaalde eigenschappen met zijn ``\emph{ouders}'' deelt. Meestal volgt hierna een \emph{mutatie}-fase: men zal de oplossing minimaal aanpassen door middel van een andere overgangsfunctie. Onder bepaalde voorwaarden wordt de gegenereerde oplossing dan in de populatie ge\"injecteerd. Om de populatie binnen de perken te houden houdt dit meestal in dat na verloop van tijd minder kwalitatieve oplossingen uit de populatie worden verwijdert.\cite{holland1992adaption-in-nat,goldberg89,melanie_mitchell_book}

\subsubsection{Simulated Annealing}

\emph{Simulated Annealing (SA)} is de eerste gepubliceerde metaheuristiek. Het is een schema gebaseerd op het \algo{Algoritme van Metropolis}\cite{Metropolis1953}. Het werkt aan de hand van \'e\'en overgangsfunctie en \'e\'en oplossing die soms de actieve oplossing wordt genoemd. Het algoritme voert telkens de overgangsfunctie uit op de actieve oplossing. De resulterende oplossing beschouwen we als de nieuwe oplossing met een kans:

\begin{equation}
\fun{p}{\mbox{accept $s_1\rightarrow s_2$}}=\fun{\min}{1,e^{\brak{\fun{\evalfun}{s_2}-\fun{\evalfun}{s_1}}/T}}
\end{equation}

Deze formule is beter bekend als de \emph{Boltzmann-verdeling} ofwel \emph{Gibbs-verdeling}\cite{}. Indien de nieuwe oplossing beter is dan de oude oplossing, we altijd accepteren, in het andere geval accepteren we met een kans die kleiner wordt naarmate het verschil in fitness-waarde groeit. In de formule staat ook een parameter $T$ ofwel \emph{temperatuur}. De temperatuur bepaalt hoe sterk de kans daalt naarmate de kloof groeit. Het is een variabele die initieel op een positief getal wordt gezet en gedurende het zoekproces langzaam naar $0$ zakt. Dit betekent dat we in het begin sterk geneigd zijn om een slechtere oplossing te accepteren. Op het einde accepteren we bijna uitsluitend oplossing die beter zijn dan hun ouder.\cite{citeulike:1612433,Cerny1985Thermodynamical}

\subsubsection{Iterated Local Search}

In de vorige sectie bespraken we \emph{Local Search}. \emph{Local Search} optimaliseert een oplossing door telkens in de omgeving van de actieve oplossing op zoek te gaan naar een betere oplossing. Deze methode leidt op termijn altijd tot een lokaal optimum. \emph{Iterated Local Search (ILS)} probeert een globaal optimum te bereiken met behulp van een zoekproces dat afwisselt tussen twee fases: in de \emph{local search} fase optimaliseert het programma de oplossing tot het in een lokaal optimum terecht komt; in de \emph{perturbatie} fase voert men een overgangsfunctie uit die met een zekere kans in staat moet zijn om een oplossing te genereren die uit het lokale optimum ontsnapt.\cite{stuetzle:1999,Glover2003}

\subsubsection{Variable Neighborhood Search}

\emph{Variable Neighborhood Search (VNS)} is een metaheuristiek die verder bouwt op \emph{Iterated Local Search}. In het geval van \emph{Variable Neighborhood Search} is er echter sprake van verschillende definities voor een omgeving $\neighbr_i$ in een iteratie zullen in de \emph{shake} fase migreren naar een random oplossing in de omgeving $\neighbr_i$ en vervolgens passen we \emph{local search} toe op basis van deze omgeving. In het geval we lange tijd geen verbetering vaststellen veranderen we van definitie voor omgeving.\cite{journals/eor/HansenM01}

\subsubsection{Tabu Search}
In het geval van \emph{Tabu Search} bestaat de omgeving uit de unie van een reeks deelomgevingen. Onder bepaalde voorwaarden kan men beslissen een deel van de omgeving of oplossingsruimte tijdelijk ontoegankelijk te verklaren: de acties of locaties worden dan tijdelijk in een ``\emph{Tabu List (TL)}'' ondergebracht. Dit kan bijvoorbeeld nuttig zijn om eerdere acties niet plots ongedaan te maken. Na en bepaald aantal iteraties worden de acties terug uit de \emph{Tabu List} gehaald en kan men deze wel terug uitvoeren.\cite{journals/cor/Glover86,DBLP:journals/informs/Glover89,citeulike:2634743,Glover:TabuSearch}

\subsection{Omzetten van beperkingen naar evaluaties}

Soms is $\hcfun$ een complexe functie met een weinig voorspelbaar gedrag. Een gevolg is dat het voor transitiefuncties geen sinecure is om een oplossingen te genereren uit de originele oplossing die nog steeds aan alle harde beperkingen voldoet. Een oplossing voor dit probleem is het omzetten van een deel de harde beperkingen $\hcfun$ in de evaluatiefunctie $\evalfun$. Oplossingen die niet aan een deel van de harde beperkingen voldoen, zullen we toch als geldige oplossingen aanzien, maar met een hoge fitness-waarde. De procedure die berekend welke oplossing uiteindelijk wordt teruggegeven wordt ook aangepast: enkel geldige oplossing kan worden teruggegeven. Een algoritme die een optimalisatieprobleem $\tupl{X,\hcfun_1\wedge\hcfun_2,\evalfun}$ oplost, kan dus inwendig een optimalisatieprobleem $\tupl{X,c_1,\evalfun-K\cdot\krdelta{c_2}}$ oplossen met $K$ een grote constante.\cite{dmathematicsforbioinformatics}

\subsection{Modelleren van Metaheuristieken}

Elke metaheuristiek die we hierboven beschreven hebben dient telkens drie belangrijke vragen in het achterhoofd te houden\cite{DBLP:journals/jc/ShonkwilerV94}:
\begin{enumerate}
 \item kan het globale optimum altijd gevonden worden door de metaheuristiek,
 \item hoe kunnen we identificeren dat we het globale optimum gevonden hebben, en
 \item hoe lang zal het duren alvorens we dit optimum gevonden hebben
\end{enumerate}

Wanneer we geen details kennen in verband met de vorm van de evaluatiefunctie $\evalfun$ spreekt het voor zich dat we enkel zeker kunnen zijn dat we een globaal optimum hebben gevonden door middel van \emph{exhaustive search}. De verwachtte tijd alvorens dit gebeurt kan echter sterk verschillen van de tijd die we dienen te besteden aan het doorzoeken van een significant deel van de zoekruimte. Berekenen wanneer we gemiddeld dit optimum zullen bereiken staat bekend als het \prbm{Hitting Time Problem}\cite{DBLP:journals/jc/ShonkwilerV94}. We zullen in de volgende subsecties een model bespreken die de gemiddelde raaktijd probeert te identificeren.

\subsubsection{Verwachtte tijd van een sequentieel proces}

Onderzoek naar de raaktijd is gepubliceerd in \cite{DBLP:journals/jc/ShonkwilerV94}. Men modelleert in deze publicatie een metaheuristiek aan de hand van een \emph{Markovketen}: een algoritme dat zich op elk moment in een toestand bevindt en de volgende toestand probabilistisch kiest, uitsluitend op basis van de vorige toestand. Een toestand wordt voorgesteld met slechts een eindig aantal bits, bijgevolg kan dus niet de volledige geschiedenis die het algoritme heeft doorlopen in de toestand worden opgeslagen.

Toegepast op het geval van een metaheuristiek zal de toestand de populatie $\PopSet_i$ op dat moment voorstellen. Verder stelt men dat de populatie een vast aantal oplossing bevat. Deze voorwaarde beperkt het model niet omdat in elk algoritme de grootte van de populatie beperkt is tegenover de geheugencapaciteit van de machine en we op momenten dat er minder individuen in de populatie zitten, de lege plaatsen kunnen opvullen met zogenaamde \emph{dummy-oplossingen}.
\paragraph{}
Elke iteratie zal het algoritme een nieuwe toestand kiezen. Dit gebeurt volgen bepaalde overgangskansen $\fun{p}{t,i,j}$: de kans om van een populatie $\PopSet_i$ naar een populatie $\PopSet_j$ te gaan op tijdstip $t$. Indien de waarde van $\fun{p}{i,j,t}$ constant blijft over de tijd $t$ dan spreken we over een \emph{stationair} proces (dit is typisch voor bijvoorbeeld een genetisch algoritme), indien de kansen in de tijd veranderen beschouwen we een \emph{niet stationair} proces. We zullen enkel het \emph{stationaire} geval beschouwen.

\paragraph{}
Een concrete uitvoer van een metaheuristiek genereert dus een Markovketen: een lijst aan toestanden (populaties) waarbij het $i$-de elementen in de lijst de populatie op tijdstip $i$ voorstelt. We kunnen de raaktijd van een Markovketen vervolgens defini\"eren als het tijdstip waarop we in een populatie terecht waar het globaal optimum deel van uitmaakt:

\begin{definition}[Raaktijd $\hittime$]
De \emph{raaktijd} $\hittime$ van een Markovketen $\PopChain$ die bestaat uit populaties $\PopSet_t$ is gedefinieerd als volgt:
\begin{equation}
\fun{\hittime}{\PopChain}=\min\accl{t|\PopSet_t\in\PopChain\wedge\ConfigOpSet\cap \PopSet_t\neq\emptyset}
\end{equation}
We kunnen deze definitie ook uitbreiden naar de raaktijd voor een zekere \emph{fitness-waarde}~\fitnessval:
\begin{equation}
\fun{\hittime}{\PopChain,\fitnessval}=\min\accl{t|\PopSet_t\in\PopChain:\exists \sol\in \PopSet_t:\fun{\evalfun}{\sol}\leq \fitnessval}
\end{equation}
\end{definition}

\paragraph{}
We zullen stellen dat we op zoek zijn naar een populatie met een oplossing met een fitness-waarde die kleiner is dan~\fitnessval. Op basis van dit criterium kunnen we populaties indelen in \emph{doel-populaties}, waar dergelijke oplossingen in voorkomen, en \emph{normale populaties}. We stellen dat er in totaal $\npop$~\emph{populaties} door het algoritme kunnen worden gegenereerd waarvan $\ntarpop$~\emph{doel-populaties}. We geven vervolgens elk van de populaties een index waarbij we de \emph{doel-populaties} eerst nummeren: $\PopSet_1,\PopSet_2,\ldots,\PopSet_{\ntarpop}$ zijn \emph{doel-populaties}, $\PopSet_{\ntarpop+1},\PopSet_{\ntarpop+2},\ldots,\PopSet_{\npop}$ \emph{normale populaties}. We kunnen nu een kansvector \probdistmeta{t} opstellen voor een gegeven tijdstip waarbij een element in \probdistmeta{t} de kans voorstelt dat het algoritme zich op dat moment in de overeenkomstige toestand (populatie) bevindt. Door de transitiekansen te herschrijven in de vorm van een transitiematrix $\transmat$ kunnen we door \probdistmeta{t} met deze matrix te vermenigvuldigen de kansverdeling voor de volgende iteratie uitrekenen.

\paragraph{}
Het ordenen van de populaties in een \emph{doel-populatie} gedeelte en een \emph{normaal} gedeelte laat toe dat we de transitiematrix $\transmat$ opdelen in $4$~deelmatrices:
\begin{equation}
\transmat=\brak{\begin{array}{cc}
J&H\\
\bridgemat&\removmat
\end{array}}
\end{equation}
Met $J$ een $\ntarpop\times\ntarpop$ matrix, $H$ een $\ntarpop\times\npop-\ntarpop$ matrix, $B$ een $\npop-\ntarpop\times\ntarpop$ matrix en $\removmat$ een $\npop-\ntarpop\times\npop-\ntarpop$ matrix. De waardes van $J$ en $H$ zijn niet interessant: eenmaal we ons in een \emph{doel-populatie} bevinden is wat daarna gebeurt irrelevant voor de \emph{raaktijd} van het algoritme. We streven er naar om met ons algoritme de waardes in $\bridgemat$ -- ook wel de \emph{bridge} genoemd -- zo hoog mogelijk te maken: deze matrix bevat immers de kansen om van een \emph{normale populatie} naar een \emph{doel-populatie} te migreren. $\removmat$ wordt ook wel de \emph{verwijderde transitiematrix} genoemd. De waardes in de matrix worden be\"invloed door het probleem (via de definities van de omgevingen) en het zoekalgoritme (de metaheuristiek in kwestie).
\paragraph{}
Net als bij de transitiematrix $\transmat$ kunnen we de probabiliteitsvector $\probdistmeta{t}$ opdelen in twee delen: een gedeelte $\probdistgoalmeta{t}$ met dimensie $\ntarpop$ en een gedeelte $\probdistnormmeta{t}$. Op basis van de transitiematrix kunnen we de probabiliteitsvector na $t$ stappen berekenen in functie van $\probdistmeta{t-1}$:
\begin{equation}
\probdistmeta{t}=\brak{\probdistgoalmeta{t}\ |\ \probdistnormmeta{t}}=\probdistmeta{t-1}\cdot\transmat=\brak{\probdistgoalmeta{t-1}+\bridgemat\cdot\probdistnormmeta{t-1}\ |\ \probdistnormmeta{t-1}\cdot\removmat}
\eqnlab{oneStepTransition}
\end{equation}
We zijn vooral ge\"interesseerd in de fractie van Markovketens die in stap $t$ naar een \emph{doel-populatie} migreren ofwel de kans dat we stap $t$ een gewenste oplossing bereiken:
\begin{equation}
\Prob{\hittime=t}=\displaystyle\sum_{i=\ntarpop+1}^{N}\brak{\probdistmeta{t-1,i}\cdot\displaystyle\sum_{j=1}^{\ntarpop}\fun{p}{t,i,j}}=\dabs[1]{\probdistnormmeta{t-1}\cdot \bridgemat}
\eqnlab{exhaust}
\end{equation}
Een ander logische gevolg uit \eqnref{oneStepTransition} zijn de transities van \emph{normale populaties} naar andere \emph{normale populaties}. De som van de kansen die in deze deelvector aanwezig zijn, is de kans dat we na deze $t$ stappen nog steeds geen acceptabele oplossing gevonden hebben:
\begin{eqnarray}
\probdistnormmeta{t}=\probdistnormmeta{t-1}\cdot\removmat=\probdistnormmeta{t-2}\cdot\removmat^2=\ldots=\probdistnormmeta{0}\cdot\removmat^t\eqnlab{remainder}\\
\Prob{\hittime>t}=\displaystyle\sum_{i=\ntarpop+1}^{\npop}\probdistmeta{t,i}=\dabs[1]{\probdistnormmeta{t}}=\dabs[1]{\probdistnormmeta{0}\cdot\removmat^t}\eqnlab{nothit}
\end{eqnarray}
Op basis van \eqnref{remainder} en \eqnref{nothit} kunnen we nu de verwachte stap berekenen waarop we een \emph{doel-populatie} zullen bereiken:
\begin{equation}
\mean{\hittime}=1+\displaystyle\sum_{i=0}^{\infty}{\Prob{\hittime>i}}=1+\displaystyle\sum_{i=0}^{\infty}{\dabs[1]{\probdistnormmeta{0}\cdot\removmat^i}}
\eqnlab{meanHit}
\end{equation}
In deze vergelijking tellen we elke kans $\Prob{\hittime=k}$ juist $k$ keer.
\paragraph{}
Vermits $\removmat$ een kansenmatrix voorstelt kunnen we stellen dat $\hat{p}_{i,j}\geq 0$. We maken verder de assumptie dat we na een arbitrair aantal stappen $\arbitraryval$, vanuit elke \emph{normale populaties} $\calP_i$ een kans bestaat dat we naar een andere \emph{normale populaties} $\calP_j$ kunnen migreren. Vermits hierdoor de matrix primitief is, en er minstens \'e\'en rij van $\removmat$ niet sommeert naar~$1$ (anders zouden we nooit in een \emph{doel-populatie} kunnen terechtkomen), weten we dat de grootste eigenwaarde $\ev[1,\removmat]<1$.

\paragraph{}
We kunnen een eigenvector benaderen door een $\onematrix$-vector een groot aantal maal toe te passen op de matrix in kwestie en vervolgens te normaliseren. Daarom kunnen we stellen dat voor een grote $t$:
\begin{equation}
\begin{array}{cc}
\arbitraryvec\cdot\removmat^t\cdot\onematrix[\npop-\ntarpop\times1]\approx\arbitraryvec\cdot\ev[1,\removmat]^t\cdot\evr[1,\removmat]^{\top}=\ev[1,\removmat]^t\cdot\metapa&\mbox{($t\gg 1$)}
\end{array}
\eqnlab{longTermAlpha}
\end{equation}
Wanneer we voor $\arbitraryvec$ de begindistributie $\probdistnormmeta{0}$ nemen, kunnen we het inwendig product tussen $\probdistnormmeta{0}$ en $\evr[1,\removmat]$ defini\"eren als $\metapa$. We kunnen vervolgens \eqnref{meanHit} en \eqnref{longTermAlpha} samennemen in een nieuwe vergelijking die een benaderende waarde voor de gemiddelde raaktijd oplevert:
\begin{equation}
\mean{\hittime}\approx 1+\dabs[1]{\probdistnormmeta{0}}+\metapa\cdot\brak{\displaystyle\sum_{i=1}^{\infty}\ev[1,\removmat]^i}=1+\dabs[1]{\probdistnormmeta{0}}+\displaystyle\frac{\metapa\cdot \ev[1,\removmat]}{1-\ev[1,\removmat]}
\end{equation}
Net zoals we de termen van dit gemiddelde benadert hebben aan de hand van \eqnref{longTermAlpha}, kunnen we de eerste termen benaderen door deze vergelijking omgekeerd toe te passen. We stellen dus dat $1+\dabs[1]{\probdistnormmeta{0}}=\metapa\cdot\brak{1+\ev[1,\removmat]^{-1}}$. Dit levert ons een ruwe schatting voor de raaktijd op:
\begin{equation}
\mean{\hittime}\approx\displaystyle\frac{\metapa}{\brak{1-\ev[1,\removmat]}\cdot\ev[1,\removmat]}
\eqnlab{hitTimeSingle}
\end{equation}

\subsubsection{Onafhankelijke parallelle Monte-Carlo simulaties}

\cite{DBLP:journals/jc/ShonkwilerV94} beschouwt ook een logische stap tot parallellisatie: $p$ processoren draaien elk onafhankelijk van elkaar een metaheuristiek, op het moment dat \'e\'en van de processoren in een \emph{doel-populatie} terechtkomt stoppen alle processoren en wordt de beste oplossing gerapporteerd. We kunnen dit fenomeen modelleren met behulp van een Markovketen waarbij elke knoop van de keten een $p$-tuple voorstelt met de populaties van de verschillende processoren in de tijdstap. Vervolgens defini\"eren we \emph{parallelle raaktijd} $\phittime$ als volgt:

\begin{definition}[Parallelle raaktijd $\phittime$]
We defini\"eren de parallelle raaktijd $\phittime$ van een Markovketen $\PopChain$ die bestaat uit $p$-tuples van populaties $\tupl{\PopSet_{t,1},\PopSet_{t,2},\ldots,\PopSet_{t,p}}$ als:
\begin{equation}
\fun{\phittime}{\PopChain}=\min\accl{t|\tupl{\PopSet_{t,1},\PopSet_{t,2},\ldots,\PopSet_{t,p}}\in\PopChain\wedge\exists i:\ConfigOpSet\cap \PopSet_{t,i}\neq\emptyset}
\end{equation}
We kunnen deze definitie ook uitbreiden naar de raaktijd voor een zekere fitness-waarde $\fitnessval$:
\begin{equation}
\fun{\phittime}{\PopChain,\fitnessval}=\min\accl{t|\tupl{\PopSet_{t,1},\PopSet_{t,2},\ldots,\PopSet_{t,p}}\in\PopChain\wedge\exists i\exists \sol\in\PopSet_{t,i}:\fun{\evalfun}{\sol}\leq \fitnessval}
\end{equation}
\end{definition}
Vermits de verschillende processoren een onafhankelijk en equivalent proces uitvoeren, kunnen we gebruik maken van het theorema van de onafhankelijke kansen met de \emph{onafhankelijke EN}-regel:
\begin{equation}
\begin{aligned}
\Prob{\phittime\geq t}&=\Prob{\hittime_1\geq t\wedge\hittime_2\geq t\wedge\ldots\wedge\hittime_p\geq t}\\
&=\Prob{\hittime_1\geq t}\cdot\Prob{\hittime_2\geq t}\cdot\ldots\cdot\Prob{\hittime_p\geq t}\\
&=\Prob{\hittime\geq t}\cdot\Prob{\hittime\geq t}\cdot\ldots\cdot\Prob{\hittime\geq t}=\Prob{\hittime\geq t}^p
\end{aligned}
\end{equation}
Op basis van deze regel kunnen we de gemiddelde parallelle raaktijd bepalen op basis van \eqnref{meanHit}:
\begin{equation}
\begin{aligned}
\mean{\phittime}&=1+\displaystyle\sum_{i=0}^{\infty}{\Prob{\phittime>i}}=1+\displaystyle\sum_{i=0}^{\infty}{\Prob{\hittime>i}^p}\\
&\approx 1+\dabs[1]{\probdistnormmeta{0}}^p+\metapa^p\cdot\brak{\displaystyle\sum_{i=1}^{\infty}\ev[1,\removmat]^{p\cdot i}}=1+\dabs[1]{\probdistnormmeta{0}}^p+\displaystyle\frac{\metapa^p\cdot\ev[1,\removmat]^p}{1-\ev[1,\removmat]^p}\\
&\approx\displaystyle\frac{\metapa^p}{\brak{1-\ev[1,\removmat]^p}\cdot\ev[1,\removmat]^{p}}
\end{aligned}
\end{equation}
De \absu{} is bijgevolg gelijk aan:
\begin{equation}
\funm{\absu{}}{p}=\displaystyle\frac{\mean{\hittime}}{\mean{\phittime}}=\displaystyle\frac{\ev[1,\removmat]^{p-1}}{\metapa^{p-1}}\cdot\displaystyle\frac{1-\ev[1,\removmat]^{p}}{1-\ev[1,\removmat]}\approx\displaystyle\frac{p\cdot\metapb^{p-1}}{\metapa^{p-1}}
\eqnlab{speedupMetaheuristic}
\end{equation}
In het laatste deel van de vergelijking vervangen we ook $\ev[1,\removmat]$ door $\metapb$. Dit is louter om de formules die hiervan afgeleid zijn leesbaar te houden.

\subsubsection{Semantiek van parameters $\metapa$ en $\metapb$}

\eqnref{speedupMetaheuristic} formaliseert de verwachte \absu{} bij een probleem. Deze formule bevat 3 parameters en kan daarom niet zomaar ge\"interpreteerd worden. Behalve het aantal processoren $p$ is het niet triviaal om de overige parameters te interpreteren.

\paragraph{}
We hebben in \eqnref{longTermAlpha} een benadering geformuleerd voor de distributie over \emph{normale populaties}. Elke initi\"ele distributie zal bijgevolg altijd convergeren naar een distributie proportioneel aan de sterkste linkse eigenvector $\evl[1,\removmat]$. Eenmaal $\probdistnormmeta{t}\approx\evl[1,\removmat]$ kunnen we stellen dat:
\begin{equation}
\conditional{\probdistnormmeta{t+1}=\probdistnormmeta{t}\cdot\removmat=\metapb\cdot\probdistnormmeta{t}}{$t\gg 1$}
\end{equation}
Bijgevolg kunnen we $\metapb$ interpreteren als de kans op lange termijn dat we vanuit een \emph{normale populaties} de volgende stap niet naar een \emph{doel-populatie} migreren. Voor elk zinvol probleem kunnen we stellen dat $\metapb$ dicht bij $N-g/N\approx 1$ zal blijven (dit is ook de oorzaak van de laatste vereenvoudiging in \eqnref{speedupMetaheuristic}). Verder geldt altijd: $0\leq\metapb<1$.

\paragraph{}
Ook de rechtse eigenvector $\evr[1,\removmat]$ heeft een betekenis. We kunnen de lengte van deze vector vrij instellen en stellen $\dabs[1]{\evr[1,\removmat]}=1$. Vermits het volgende geldt:
\begin{equation}
\conditional{A^t\approx\ev[A]^t\cdot\evr[A]\cdot\evl[A]^T}{$t\gg1$}
\end{equation}
is genormaliseerde rechtse eigenvector een probabiliteitsvector die aangeeft in welke mate een populaties bijdragen tot het behoud in een \emph{normale populaties}. Wanneer we dus de $i$-de gewone populatie beschouwen en het $i$-de element van $\evr[1,\removmat]$ is klein, is er een grote kans dat we in een doel-toestand terecht zullen komen.

\paragraph{}
De interpretatie van de rechtse eigenvector vormt de basis voor de interpretatie van $\metapa$. Vermits $\metapa$ het inwendig product is tussen de probabiliteitsvector $\probdistnormmeta{0}$ en $\evr[1,\removmat]$. Dit inwendig product is proportioneel met de cosinus van de hoek tussen beide vectoren:
\begin{equation}
\fun{\cos}{\probdistnormmeta{0},\evr[1,\removmat]}=\displaystyle\frac{\probdistnormmeta{0}^T\cdot\evr[1,\removmat]}{\dabs{\probdistnormmeta{0}}\cdot\dabs{\evr[1,\removmat]}}=\displaystyle\frac{\metapa}{\dabs{\probdistnormmeta{0}}\cdot\dabs{\evr[1,\removmat]}}
\end{equation}
Uit de definitie van de cosinus kunnen we bovendien stellen dat:
\begin{equation}
\dabs{\evr[1,\removmat]}=\displaystyle\frac{\dabs{\evl[1,\removmat]}}{\fun{\cos}{\evl[1,\removmat],\evr[1,\removmat]}}
\end{equation}
Bijgevolg kunnen we stellen dat:
\begin{equation}
\metapa=\displaystyle\frac{\dabs{\hat{\alpha}_0}\cdot\fun{\cos}{\probdistnormmeta{0},\evr[1,\removmat]}}{\dabs{\evl[1,\removmat]}\cdot\fun{\cos}{\evl[1,\removmat],\evr[1,\removmat]}}
\eqnlab{sigmaMeaning}
\end{equation}
$\metapa$ is bijgevolg de ratio tussen de projecties van enerzijds de initi\"ele kansverdeling $\probdistnormmeta{0}$ en anderzijds de linkse eigenvector $\evl[1,\removmat]$ op de rechtse eigenvectoren $\evr[1,\removmat]$. Wanneer $\metapa$ klein is verwachten we sneller een oplossing te vinden. De factoren die hiertoe bijdragen zijn dus:
\begin{itemize}
 \item Een kleine $\dabs{\probdistnormmeta{0}}$. Vermits de som van $\probdistnormmeta{0}$ neerkomt om de kans dat onze beginpopulatie geen doelpopulatie is, streven we er naar om deze zo laag mogelijk te houden.
 \item Wanneer $\probdistnormmeta{0}$ en $\evr[1,\removmat]$ niet gelijkaardig zijn, dan zijn de populaties waar we met een grote kans in starten niet de populaties die met een grote kans naar een \emph{normale populaties} migreren in de volgende stap. Wanneer de cosinus tussen de vectoren dus klein is, verwachten we in de eerste stappen naar een \emph{doel-populatie} te migreren.
 \item Wanneer de linkse en de rechtse eigenvector gelijk zijn, is de matrix $\removmat$ symmetrisch. Indien de matrix symmetrisch is, verwachtten we doorgaans minder populaties waarnaar we kunnen migreren, maar vervolgens niet uit kunnen geraken. Indien de matrix immers symmetrisch is, is de kans om vanuit een populatie in een andere populatie te migreren immers dezelfde om er vervolgens terug uit te geraken. Daarom streven we naar een zo minimaal mogelijk hoek tussen de twee.
\end{itemize}
Uit de formule kunnen we afleiden dan $\metapa$ aan slechts \'e\'en kant begrensd is: $0<\metapa$.

\subsubsection{Superlineaire Speed-up}

Vermits $0\leq\metapb<1$ en $0<\metapa$, kunnen we met behulp van \eqnref{speedupMetaheuristic} bepalen welke \absu{} mogelijk is. Opmerkelijk is dat indien $\metapa<\metapb$, \abslsu{} mogelijk is. \auth{Shonkwiler} en \auth{Van Vleck} ontwikkelen in hun paper\cite{DBLP:journals/jc/ShonkwilerV94} enkele metaheuristieken voor problemen waar men ook effectief \abslsu{} kan vaststellen. Uit de sectie rond parallelle algoritmes zouden we echter kunnen afleiden dat dit niet mogelijk is.

\paragraph{}
De anomalie zit dan ook waarschijnlijk in het feit dat de parallelle variant van de Monte-Carlo simulatie geen zuivere metaheuristiek is: wanneer we immers het aantal processoren opdrijven, drijven we ook het aantal initi\"ele populaties op. Zoals we uit \eqnref{sigmaMeaning} kunnen afleiden wordt $\metapa$ klein indien de beginverdeling $\probdistnormmeta{0}$ klein is of sterk afwijkt van $\evr[1,\removmat]$. In dat geval loont het dus eerder de moeite van telkens nieuwe populaties te genereren dan deze populaties te laten evolueren. We kunnen dus stellen dat in het geval $\metapa<\metapb$, de metaheuristiek slecht is opgesteld. De voorbeelden die \cite{DBLP:journals/jc/ShonkwilerV94} aanhaalt zijn dan ook problemen in \comp{P}, of problemen met slecht ge\"implementeerde metaheuristieken.

\subsubsection{Anomalie\"en in het model}
f
Het voorgestelde model vertoond verder nog enkele anomalie\"en. Hieronder geven we een bondig overzicht.

\paragraph{}
We hebben het proces als een stationaire Markovketen gemodelleerd. Metaheuristieken hebben eerder een dynamisch karakter: op basis van kennis uit het verleden, veranderen de transitiematrices per tijdstap. In het geval van bijvoorbeeld \emph{Simulated Annealing} gebeurt dit volgens een vast patroon en kunnen we sommige effecten modelleren\cite{}. Meestal echter veranderen de kansen op basis van de bezochte populaties. In dat geval is het minder evident om een model op te stellen.

\paragraph{}
In het model vraagt het genereren van een populatie dezelfde hoeveelheid tijd als een transitie. In de praktijk verwachten we dat in heel wat gevallen de tweede stap sneller zal verlopen (omdat de configuraties en populaties maar gedeeltelijk aangepast zullen worden). Dit is ook een aspect die pleit voor metaheuristieken: we besparen tijd door de transities sneller uit te voeren dan het genereren van nieuwe configuraties.

\paragraph{}
Niet elke transitie verloopt even snel: sommige transities vragen inherent meer tijd omdat bijvoorbeeld een groter deel van de populatie wordt aangepast of er veranderen meer variabelen in een configuratie van waarde. Vermits het programma draait op een processor die maar een eindig aantal bits in constante tijd kan veranderen\footnote{We beschouwen geen vector computer.} zullen sommige transities meer tijd kosten.

\paragraph{}
De meeste metaheuristieken de voorkeur aan migratie naar sterke populaties. Hiervoor worden algoritmes zoals \emph{Local Search} gebruikt. Het spreekt voor zich dat \emph{Local Search} transities meestal meer tijd kosten omdat de evaluatiefuncties onderweg voortdurend moeten worden uitgerekend. We kunnen dit probleem oplossen door het introduceren van dummy-populaties: populaties die de toestanden onderweg voorstellen en zo dus meer tijdstappen genereren. Het is echter minder evident om in dat geval de parameters $\metapa$ en $\metapb$ te berekenen.

\subsubsection{Minimale Speed-up}

Metaheuristieken worden ge\"implementeerd als een evoluerende populatie (mogelijk bestaat de populatie uit \'e\'en individu) met transitiefuncties. De reden is dat men verwacht dat men iets uit het verleden kan leren en goede oplossingen meestal minimaal van elkaar verschillen (dit kan beargumenteerd worden met een studie in \cite{Kalnis02viewselection}). Indien we aan deze assumptie geen geloof hechten kunnen we op een andere manier de optimale oplossing proberen te vinden. Vermits de variabelen en de bijbehorende domeinen op voorhand gekend zijn, kan een programma een toevallige oplossing genereren. Bovendien kunnen we een programma zo ontwerpen dat het uitsluitend oplossingen genereert die nog niet eerder gegenereerd werden in dit in een tijdscomplexiteit onafhankelijk van het aantal eerder gegenereerde oplossingen.
\paragraph{}
Stel dat het domein exact \'e\'en optimale oplossing bevat, dan is de kans dat we in iteratie $t$ deze waarde vinden gelijk aan:
\begin{equation}
\Prob{\theta=t|\theta\geq t}=\guards{
0&\mbox{if }t>N\\
1/N-t+1&\mbox{otherwise}
}
\end{equation}
Met $N$ het aantal mogelijke configuraties ($N=\bigoh{\prod_i\abs{A_i}}$). In dat geval is gemiddelde raaktijd:
\begin{equation}
\mean{\hittime}=\displaystyle\sum_{i=1}^N\Prob{\hittime\geq i}=\displaystyle\sum_{i=1}^N\displaystyle\frac{i}{N}=\displaystyle\frac{N+1}{2}
\end{equation}
In het geval dat we dit algoritme op $p$ machines laten draaien bekomen we:
\begin{equation}
\mean{\phittime}=\displaystyle\sum_{i=1}^N\Prob{\phittime\geq i}=\displaystyle\sum_{i=1}^N\Prob{\hittime\geq i}^p=\displaystyle\frac{1}{N^p}\displaystyle\sum_{i=1}^Ni^p\approx\displaystyle\frac{N}{p+1}
\end{equation}
De laatste benadering bekomen we omdat de som een veelterm van graad $p+1$ is met $1/p+1$ als leidende co\"effici\"ent. Bijgevolg is de \absu{} bij benadering gelijk aan:
\begin{equation}
\mbox{\absu{}}=\displaystyle\frac{\mean{\hittime}}{\mean{\phittime}}\approx\displaystyle\frac{\brak{N+1}\cdot\brak{p+1}}{2\cdot N}\approx\displaystyle\frac{p+1}{2}
\eqnlab{minimalSpeedupMetaheuristic}
\end{equation}
De formule is verder te veralgemenen naar $g$ gewenste oplossingen maar leidt tot dezelfde \absu{}. Men dient wel op te merken dat er doorgaans betere algoritmen bestaan om naar de oplossing te zoeken dan louter per toeval configuraties te genereren en in dat geval is het meestal minder evident om dezelfde \absu{} te realiseren.



\subsection{Parallelliseren van metaheuristieken in de praktijk}

Een referentiewerk in verband met het uitvoeren van metaheuristieken op verschillende processoren in de praktijk is \work{Parallel Metaheuristics: A New Class of Algorithms} van \auth[Alba2005book]{Enrique Alba}. In het boek maakt men een onderscheid tussen \emph{Local Search Metaheuristics (LMS)} en \emph{Evolutionary Algorithms (EA)} anderzijds.
\paragraph{}
Onder \emph{Local Search Metaheuristics} verstaan we metaheuristieken die slechts met \'e\'en actieve oplossing werken. Bij deze metaheuristieken ziet men drie bronnen tot parallellisme:
\begin{enumerate}
 \item \emph{Parallel multistart}: de processoren starten met een verschillende initi\"ele populatie en werken min of meer onafhankelijk. Dit is het parallellisatie-paradigma die we in de modellering hebben beschouwd.
 \item \emph{Parallel moves}: er is sprake van \'e\'en gedistribueerde actieve oplossing. Elke processor berekend vervolgens een kandidaat die als volgende actieve oplossing wordt voorgedragen. Uit deze verzameling van oplossingen wordt dan een nieuwe gedistribueerde actieve oplossing gekozen. In het geval we een \emph{Local Search} stap uitvoeren kunnen we bijvoorbeeld ook elke processor een deel van de volledige omgeving laten afzoeken.
 \item \emph{Move acceleration}: een migratie kan er soms uit bestaan dat een significant deel van de oplossing verandert. Bovendien kan de evaluatiefunctie zelf ook moeilijk uit te rekenen zijn. In het geval van \emph{move acceleration} wordt de oplossing opgedeeld in min of meer onafhankelijk delen. Elke processor past een deel van de configuratie aan en rekent de verandering van de fitness-waarde met betrekking tot dit deel uit. Meestal is nog een \emph{post-processing} fase vereist om de uiteindelijke fitness-waarde te berekenen. In sommige modellen laat men fouten toe in de evaluatiefunctie en berekent men de fitness-waarde maar sporadisch correct.
\end{enumerate}

\paragraph{}
In het geval van \emph{Evolutionary Algorithms} wordt er gerekend met een populatie van oplossingen. Er worden twee vormen van parallellisme voorgesteld:
\begin{enumerate}
 \item \emph{Parallel population}: men kan ook voor elke processor en onafhankelijke populatie beschouwen waarop een evolutionair algoritme werkt. Meestal gaat dit enigszins gepaard met kruisbestuiving: het uitwisselen van sterke oplossingen. Meestal noemt een genetisch algoritme waarbij men deelpopulaties beschouwd een \emph{Island Model}\cite{Whitley98theisland,parallelgeneticalgorithms}.
 \item \emph{Parallel computation}: Operaties zoals het berekenen van de fitness-waarde moeten op alle oplossingen in de populatie worden berekend. Vermits oplossingen onafhankelijke entiteiten zijn, kan men het berekenen van deze waarden inherent parallelliseren.
\end{enumerate}

\paragraph{}
In de bovenstaande modellen tot parallellisatie zijn de bronnen geordend in stijgende granulariteit. Meestal introduceert een fijnere granulariteit echter ook problemen in verband met mogelijke \absu{}: na elke stap worden de processoren opnieuw gesynchroniseerd. Op het moment dat een processor klaar is met zijn werk dient er gewacht te worden tot ook andere processoren deze \emph{barrier} bereiken. Dit introduceert dan ook een vorm van overhead. \cite{conf/glvlsi/HaldarNCB00} rapporteert bijvoorbeeld een negatieve \absu{} door het grote aantal synchronisatiestappen.

\paragraph{}
Andere bronnen spelen dan weer vooral bij een lagere granulariteit: het is bijvoorbeeld mogelijk dat na verloop van tijd twee populaties in een parallel evolutionair algoritme convergeren. De resultaten uit twee gelijkaardige populaties zijn meestal ook gelijkaardig, waardoor er dus weinig winst geboekt wordt met het uitvoeren van het algoritme op verschillende processoren.

\paragraph{}
\auth{Crainic} en \auth{Toulouse}\cite{crainicAndToulouse} delen de parallellisatie van metaheuristieken op in drie algemenere types. Onder \emph{Type 1} vallen de \emph{Move acceleration}, \emph{Parallel moves} en \emph{Parallel computation} paradigma's van \auth{Alba}. Men stelt in\cite{crainicAndToulouse} dat dit type van parallellisatie uitsluitend probeert om operaties of evaluaties te versnellen. Wanneer men echter het algoritme op een sequenti\"ele processor draait met eenzelfde aantal iteraties, verwachten we dat dezelfde elementen in de oplossingsruimte werden onderzocht. \emph{Type 3} komt overeen met \emph{Parallel multistart} en \emph{Parallel population}. \auth{Crainic} en \auth{Toulouse} argumenteren hier dat al deze technieken leiden tot parallelle verkenning van dezelfde zoekruimte. \emph{Type 2} is een vorm van parallellisme die in \auth{Alba} minder aan bod komt: het opdelen van de zoekruimte. Dit gebeurt door een deel van de variabelen vaste waardes te laten aannemen, de overige variabelen worden dan geoptimaliseerd door de verschillende processoren. Meestal kiest men per processor andere variabelen. Op vaste tijdstippen zal een processor vervolgens de configuraties van de verschillende processoren samenvoegen in \'e\'en globale oplossing. Omdat dit systeem sommige delen van de configuratieruimte onbezocht kan laten worden op geregelde tijdstippen nieuwe oplossingsruimtes aan de processoren toegekend.

\paragraph{}
\auth{Crainic} en \auth{Toulouse} maken ook een onderscheid in \emph{type 3} tussen \emph{interagerende processen} en \emph{niet-interagerende processen}. In het tweede geval wisselen de processen ook bepaalde aspecten uit in het zoekproces. Men verwacht dat met behulp van deze informatie er betere strategie\"en kunnen worden ontwikkeld die een metaheuristiek sneller naar de oplossing zullen leiden.

\subsubsection{Empirische resultaten}

\auth{Alba} geeft in zijn boek een uitgebreid overzicht over verschillende pogingen om metaheuristieken te parallelliseren. In een groot aantal families van metaheuristieken is \ablsu{} geen evidentie. In het geval van \emph{Ant Colony Optimisation (ACO)} bijvoorbeeld rapporteren zowel \cite{Souto2004,Randall2002,Delisle2001,Catalano:2001:PRH:761889.761897} lage effici\"entie (meestal rond de 0.40) die meestal daalt naarmate het aantal processoren toeneemt. Andere paradigma's, zoals bijvoorbeeld \emph{Tabu Search}, halen wel sterke resultaten die meestal \ablsu{} benaderen.

\subsubsection{Speed-up als een goede metriek?}
Empirische resultaten tonen dat de empirische \absu{} sterk kan vari\"eren naargelang het paradigma van de metaheuristiek. Ook wanneer men een sterke \absu{} realiseert, ontbreken harde garanties dat dit op alle probleeminstanties het geval zal zijn. \cite{crainicAndToulouse} plaats daarom vraagtekens bij de betekenis van \absu{}.

\paragraph{}
Omdat we meestal de exacte oplossing niet kennen is de \absu{} moeilijk te verifi\"eren: een parallel algoritme kan snel sterke oplossingen genereren, maar zal misschien niet significant sneller de echte oplossing vinden. Bovendien zal men meestal de uitvoer stopzetten alvorens een metaheuristiek de oplossing heeft gevonden. \cite{crainicAndToulouse} stelt daarom drie andere metrieken voor: kwalitatief sterkere oplossingen gedurende een significant deel van het zoekproces, robuustere systemen die meer garantie bieden op een sterke oplossing, of een algoritme die de algemene tijdscomplexiteit naar omlaag haalt.

\subsubsection{Parallellisatie met behulp van aangepast hardware}
Het boek besteed ook aandacht aan parallellisatie met behulp van hardware: simulaties tonen aan dat een processor soms een significante hoeveelheid rekentijd besteed aan communicatie met andere processoren. Door hardware te ontwikkelen kan men de rekentijd verder beperken. Sommige metaheuristieken zijn bijvoorbeeld op een \emph{Field Programmable Gate Array (FPGA)} ge\"implementeerd\cite{conf/glvlsi/HaldarNCB00,conf/fpt/GuntschMSDESS02,journals/gpem/Martin01}.