\chapter{Definities en State-of-the-Art}
\chplab{1}
\chapterquote{Il ne suffit pas d'\'enoncer une d\'efinition, il faut la pr\'eparer et il faut la justifier.}{Henri Poincar\'e}

In de inleiding hebben we de kort de verschillende concepten besproken die in deze thesis een belangrijke rol zullen spelen. In dit hoofdstuk gaan we hier dieper op in: we formaliseren de concepten in definities en geven een kort overzicht van de belangrijkste wetmatigheden rond deze concepten.

\section{Parallelle algoritmes}

\subsubsection{Motivatie}

De ``Wet van Moore''\cite{4785860} stelt dat het aantal transistors verdubbelt elke achttien maanden. De klokfrequentie stagneert echter en is door fysische grenzen niet langer makkelijk te verhogen. Het gevolg van deze evolutie is dat complexe problemen enkel uitgerekend kunnen worden indien men voldoende rekentijd beschikbaar stelt.

\paragraph{}
Een reactie is de introductie van het ``\emph{parallel rekenen}'' ofwel ``\emph{parallel computing}''. Een probleem wordt opgelost door programma's die op verschillende processoren tegelijk te draaien en elk een deel van het probleem oplossen. Door berichten uit te wisselen tussen de verschillende processoren of door een gemeenschappelijk geheugen aan te bieden communiceren de programma's die op de verschillende processoren draaien met elkaar.

\paragraph{}
Door met verschillende processoren te werken hoopt men de rekentijd drastisch naar beneden te kunnen halen. Dit is echter niet de enige motivatie: doorgaans verbruiken zogenaamde multi-core processoren - processoren die andere hardware zoals geheugens delen - ook minder energie. Men kan dus ook beogen de aanwezige hardware effici\"enter te gebruiken.

\paragraph{}
Sommige problemen kunnen bovendien enkel opgelost worden met parallelle algoritmen: weersimulaties houden variabelen bij voor heel wat locaties op de aarde. Deze variabelen leiden tot het gebruiken van grote hoeveelheden geheugen, meestal kan men niet al de data in het geheugen van \'e\'en machine opslaan. Door elke machine een deel van de data te laten opslaan en manipuleren kan dit probleem worden opgelost. Parallelle algoritmes worden ook ingeschakeld wanneer de data gevoelig is en niet zomaar kan worden uitgewisseld: indien bijvoorbeeld verschillende bedrijven bijvoorbeeld een globale planning willen opmaken, maar geen details over de interne werking openbaar wensen te maken, kunnen parallelle algoritmes een oplossing bieden\cite{Gaspero_amultiagent}.

\subsubsection{Prestaties van parallelle algoritmen}

De prestaties van een parallel algoritme worden meestal gemeten op basis van \emph{speed-up}: de mate waarin we virtueel de kloksnelheid kunnen opdrijven. We defini\"eren eerst enkele concepten waarna we kort een taxonomie hieromtrent toelichten.

\begin{definition}[Wall time, Speed-up, Effici\"entie\cite{Alba2005book}]
We defini\"eren de \emph{wall time} $T$ als de tijd tussen de start van het algoritme en het moment waarop het algoritme stopt. De \emph{wall time} maakt abstractie van het aantal processoren. De \emph{speed-up} is de verhouding tussen de \emph{wall-time} bij \'e\'en processor $T_1$ en de \emph{wall-time} bij $p$ processoren $T_p$:
\begin{equation}
\funm{speed-up}{p}=\displaystyle\frac{T_1}{T_p}
\end{equation}
Indien de algoritmen stochastisch van aard zijn, wordt de verhoudingen tussen de gemiddelde \emph{wall-time} gebruikt.
Wanneer we de \emph{speed-up} delen door het aantal processoren $p$ spreken we over de \emph{effici\"entie}:
\begin{equation}
\funm{effici\"entie}{p}=\funm{speed-up}{p}/p
\end{equation}
\end{definition}

\paragraph{}
Men streeft ernaar dat de \emph{speed-up} in het geval van $p$ processoren gelijk is aan $p$. Dit fenomeen noemt men \emph{lineaire speed-up}. Het komt echter voor dat bij het uitvoeren van een algoritme op $p$ processoren, het algoritme minder snel werkt dan het geval met $1$ processor. Dan spreken we over \emph{negatieve speed-up}.

\paragraph{}
Indien men een voor een ineffici\"ent algoritme een parallel equivalent schrijft, stelt men vaak een lineaire speed-up vast. Dit komt omdat een na\"ief algoritme meestal geen relaties tussen de verschillende componenten in de invoer zal uitbuiten. De lineaire speed-up is bijgevolg eerder optimistisch. Een sterkere metriek is daarom de \emph{strong speed-up}. In dit geval wordt de snelste parallelle implementatie tegenover de sterkste sequenti\"ele implementatie geplaatst. Omdat algoritmes in een parallelle context meestal maar een beperkt deel van de data ter beschikking hebben, wordt het ontwikkelen van \emph{lineaire speed-up} bijgevolg complexer en in sommige gevallen zelfs onmogelijk.

\paragraph{}
In eerder uitzonderlijke omstandigheden stelt men effectief superlineaire versnellingen vast. Dit is te wijten aan het effici\"enter gebruik van de aanwezig hardware. Cache is hierbij een uitstekend voorbeeld: bij multi-core processoren hebben de verschillende ``\emph{kernen}'' ofwel ``\emph{cores}'' meestal een eigen segment aan cache. Sommige gegevens worden gebruikt door alle processoren, bijgevolg wordt deze data in de gemeenschappelijke cache opgeslagen. Een gevolg is dat er meer ruimte beschikbaar is in de aparte caches voor specifieke data. Men noemt het effect van superlineaire versnellingen dan ook meestal het ``\emph{cache-effect}''\cite{cacheEffect}.

\subsubsection{Beperkingen en oplossingen}

Het verhogen van de snelheid met behulp van parallelle algoritmen is meestal een feit. Het optekenen van lineaire speed-up is echter geen evidentie. Dit komt onder meer door de ``\emph{Wet van Amadahl}''\cite{Amdahl:1967:VSP:1465482.1465560}. De meeste algoritmes hebben een zekere nood aan het sequentieel uitvoeren van bepaalde instructies. De Wet van Amadahl stelt dat gegeven de fractie van het aantal verplicht sequenti\"ele instructies, er een plafond bestaat en dat men met een willekeurig aantal processoren altijd onder dit plafond zal blijven. De ``\emph{Wet van Gustafson}''\cite{Gustafson:1988:RAL:42411.42415} stelt dan weer dat wanneer we de probleemgrootte arbitrair kunnen opdrijven, programma's wel een \emph{lineaire speed-up} kunnen halen. Dit komt omdat in de meeste gevallen de fractie aan de nodige sequenti\"ele instructies verwaarloosbaar klein wordt. Vermits we vooral ge\"interesseerd in het parallelliseren van grote optimalisatieproblemen, behoort \emph{lineaire speed-up} misschien alsnog tot de mogelijkheden. Een belangrijke opmerking is dat beide theorie\"en geen rekening houden met de eventuele overhead die bij parallelle algoritmen komt kijken zoals bijvoorbeeld het doorsturen van data over een netwerk.

\subsection{De belangrijkste parallellisatie paradigma}

Meestal beschouwd men twee verschillende modellen met betrekking tot parallellisatie: \emph{Message Passing Interface (MPI)} en \emph{Tuple Space}. We geven hieronder een korte samenvatting.

\subsubsection{Message Passing Interface}

In het geval van \emph{MPI} beschouwen we een set \emph{agents}: processoren die onafhankelijk werken op een eigen stuk geheugen. Deze agenten interagerend door het uitwisselen van berichten over een netwerk. Dit hoeft niet te betekenen dat de agenten ook effectief draaien op verschillende machines: men kan op elke \emph{core} van een machine een onafhankelijke agent laten werken en vervolgens de boodschappen laten bezorgen met behulp van de faciliteiten die de meeste besturingssystemen aanbieden.

\paragraph{}
In het geval de \emph{agents} wel degelijk op verschillende machines draaien werken ze meestal volgens een bepaalde \emph{topologie}: een structuur die bepaalt welke machines met elkaar verbonden zijn. Een belangrijk aspect in \emph{MPI} is ``\emph{Group Communication}'': agenten die met een significant gedeelte van de andere agenten tegelijk communiceren. Voor elke topologie zijn er dan ook algoritmes uitgewerkt om het aantal berichten tot een minimum te beperken.

\subsubsection{Tuple Space}

Een \emph{Tuple Space} is een model waarbij agenten kennis hebben van een globale wereld: de \emph{Tuple Space}. Elke agent kan tuples toevoegen in de tuple space en een query op de ruimte uitvoeren. Door tuples toe te voegen die dan door andere agenten worden verwerkt ontstaat er een communicatieprincipe. Een \emph{tuple space} verschilt echter van een \emph{message passing interface} omdat men meer abstractie maakt van de bestemming van een boodschap.

\section{Optimalisatieproblemen}

We beginnen deze sectie met een formele definitie van een optimalisatieprobleem:

\begin{definition}[Optimalisatieprobleem]%, harde beperkingen, evaluatiefunctie, fitness-waarde
Een optimalisatieprobleem $\OpProblem$ is een tuple $\OpProblem=\tupl{\ConfigSet=\VarDom_1\times \VarDom_2\times\ldots\times \VarDom_{\nvar},\hcfun,\evalfun}$ waarbij $\ConfigSet$ een verzameling is van een set configuraties voor $\nvar$ variabelen, $\funsig{\hcfun}{\ConfigSet}{\BBB}$ een afbeelding van zo'n configuratie naar een Booleaanse waarde, die bepaald of de configuratie voldoet aan de ``harde beperkingen''. $\funsig{\evalfun}{\ConfigSet}{\RRR}$ stelt een evaluatiefunctie voor die bepaald in welke mate een configuratie wenselijk is. De waarde van de evaluatie van een configuratie \fun{f}{x} wordt ook wel de fitness-waarde genoemd.
\end{definition}
Bij een optimalisatieprobleem gaan we op zoek naar een configuratie $x\in\ConfigSet$ die aan de harde beperkingen voldoet en de evaluatiefunctie optimaliseert. Meestal maakt men het onderscheid tussen een minimalisatie en een maximalisatie. In deze thesis zullen we altijd we een bij een optimalisatieprobleem altijd streven naar een configuratie $x\in\ConfigSet$ met een zo laag mogelijk evaluatie \fun{f}{x}. We kunnen echter eenvoudig elk maximalisatieprobleem $\tupl{\ConfigSet,\hcfun,\evalfun}$ omzetten in een minimalisatieprobleem $\tupl{\ConfigSet,\hcfun,\evalfuna}$ met $\funsigimp{\evalfuna}{\ConfigSet}{\RealSet}{x}{-\fun{\evalfun}{x}}$. Formeel zoeken we dus naar een configuratie \xstar{} die we het \emph{globaal optimum noemen}.

\begin{definition}[Globaal optimum $\bestSol$]
Een globaal optimum voor een zoekprobleem $\OpProblem=\tupl{\ConfigSet,\hcfun,\evalfun}$ is een configuratie $\bestSol$ waarbij:
\begin{equation}
\bestSol=\displaystyle\argmin_{\sol\in\ConfigValSet}\fun{\evalfun}{\sol}\mbox{ met }\ConfigValSet=\accl{\sol|\forall\sol\in\ConfigSet:\fun{\hcfun}{\sol}=\true}
\end{equation}
\end{definition}

Het is niet ongewoon dat er verschillende configuraties zijn met een gelijkaardige fitness-waarde. Dit geldt tevens voor het globaal optimum. Daarom defini\"eren we ook een optimum-set $\calXop$: een set met alle configuraties met een minimale fitness-waarde voor het probleem.

\begin{definition}[Optimum-set $\ConfigOpSet$]
Een optimum-set $\ConfigOpSet$ voor een zoekprobleem $\OpProblem=\tupl{\ConfigSet,\hcfun,\evalfun}$ is een set van geldige configuraties $\sol\in\ConfigValSet$ waarvoor geldt:
\begin{equation}
\calXop=\accl{\sol|\sol\in\ConfigValSet\wedge\fun{\evalfun}{\sol}=\fun{\evalfun}{\bestSol}}
\end{equation}
\end{definition}

\paragraph{}
In een algemeen geval kunnen de domeinen $A_i$ van de variabelen $x_i$ oneindig groot zijn en bijvoorbeeld $\RRR$ omvatten. Geen enkele machine met een eindig geheugen kan echter alle elementen uit een domein met oneindig veel elementen voorstellen. We zullen daarom altijd de domeinen $A_i$ als eindig beschouwen. In het geval het domein van een variabele in werkelijkheid oneindig is, discretiseren we dus dit domein en beperken we het aantal elementen met een onder- en bovengrens. Indien er door discretisatie fouten worden ge\"introduceerd, kunnen we deze oplossen door het domein fijner te discretiseren.
\paragraph{}
Vermits zowel de harde beperkingen $\hcfun$ als de evaluatiefunctie $\evalfun$ hier een ``\emph{blackbox}'' zijn, zullen we om $\bestSol$ te berekenen, over een significant deel van de verzameling $\ConfigSet$ moeten itereren. We verwachten dus dat de tijdscomplexiteit om een dergelijke oplossing te vinden gelijk is aan:
\begin{equation}
\bigoh{\abs{\ConfigSet}}=\bigoh{\displaystyle\prod_{i=1}^\nvar\abs{\VarDom_i}}
\end{equation}
Indien we de assumptie maken dat alle domeinen dezelfde zijn dan bekomen we:
\begin{equation}
\bigoh{\abs{\ConfigSet}}=\bigoh{\abs{\VarDom_1}^\nvar}\mbox{ indien }\forall \VarDom_i,\VarDom_j: \VarDom_i=\VarDom_j
\end{equation}
We zien dus dat deze tijdscomplexiteit exponentieel stijgt met het aantal variabelen~$\nvar$. Optimalisatieproblemen in het algemeen liggen dan ook in \comp{NP-hard}.

\subsection{Complexiteit van optimalisatieproblemen}

Sommige optimalisatieproblemen liggen in \comp{P}. \algo{Karmarkar's algoritme}\cite{linearProgrammingInP} bijvoorbeeld lost het \prbm{lineaire optimalisatie} probleem op in \bigoh{\nvar^{3.5}L} met $\nvar$ het aantal variabelen en $L$ de diepte van de discretisatie in bits. Dit komt omdat we beperkingen plaatsen op de vorm van de evaluatiefunctie $\evalfun$ en de harde beperkingen $\hcfun$. Bij lineair programmeren betekent dit dat de evaluatiefunctie kan geschreven worden als het inwendig product tussen de vector van de variabelen en een vector met constanten. Het harde beperkingen moeten voor te stellen zijn zodat wanneer we de vector met de variabelen vermenigvuldigen met een matrix met constante elementen, alle elementen in de resulterende vector kleiner zijn dan een andere vector met constante elementen. Ook andere optimalisatieproblemen zoals bijvoorbeeld \prbm{Maximum Flow} en \prbm{Minimum Spanning Tree} zijn problemen die met polynomiale algoritmen kunnen worden opgelost.

\paragraph{}
Toch is er weinig ruimte voor optimisme. Een logische veralgemening van \prbm{Lineaire optimalisatie} is immers \prbm{Kwadratische optimalisatie}. Onder sommige omstandigheden kunnen we dit probleem reduceren naar een geval van \prbm{Lineaire Optimalisatie}\cite{Kozlov1980223}, maar een algemeen \prbm{Kwadratisch optimalisatie} probleem ligt in \comp{NP-hard}\cite{qpInNP}. Ook andere bekende optimalisatieproblemen zoals \prbm{Travelling Salesman Problem (TSP)} en \prbm{Integer Programming (IP)} liggen in \comp{NP-hard}.

\paragraph{}
Tot slot dient men in de context van optimalisatieproblemen een kanttekening maken dat een polynomiaal algoritme meestal niet meteen impliceert dat dit ook op kleine gevallen sneller werkt dan zijn exponenti\"ele tegenhangers. Een populaire methode bij het oplossen van \prbm{Lineaire optimalisatie} is bijvoorbeeld het \algo{Simplex}-algoritme. Klee en Minty\cite{klee:1972} construeerden echter een een geval waarbij het algoritme exponentieel veel tijd vraagt. Toch is \algo{Simplex} in de meeste gevallen sneller dan \algo{Karmarkar's algoritme}.

\section{Heuristieken}

Hoewel de meeste optimalisatieproblemen \comp{NP-hard} zijn, is in een praktische context de configuratie met een optimale evaluatiefunctie net van cruciaal belang. Voor de meeste toepassingen is een configuratie die aan de harde beperkingen voldoet en de fitness-waarde van de echte oplossing benadert voldoende. In dat geval wordt meestal een heuristiek ge\"implementeerd:

\begin{definition}[Heuristiek]
Een heuristiek is een programma die gegeven een optimalisatieprobleem $\OpProblem=\tupl{\ConfigSet,\hcfun,\evalfun}$ een oplossing berekent $\goodSol$ in een redelijke tijd. Doorgaans voldoet deze oplossing aan de harde beperkingen ($\fun{\hcfun}{\goodSol}=\true$) en ligt de voorgestelde oplossing $\goodSol$ in fitness-waarde niet ver van de werkelijke oplossing $\bestSol$.
\end{definition}

Deze definitie blijft redelijk vaag en geeft dan ook veel ruimte voor interpretatie. Doorgaans verwachten we dat het algoritme stop in polynomiale tijd en in de meeste gevallen worden er ook beperkingen gezet op hoe ver de fitness-waarde $\fun{\evalfun}{\goodSol}$ mag afwijken van de optimale fitness-waarde $\fun{\evalfun}{\bestSol}$, al zijn beide voorwaarden niet strikt noodzakelijk.

%Minsky\cite{minskyHeuristic} schrijf hierover:
% \begin{quote}
% ``Hints'', ``suggestions'', or ``rules of thumb'', which only usually work are called heuristics. A program which works on such a basis is called a heuristic program. It is difficult to give a more precise definition of heuristic program - this is to be expected in the light of Turing's demonstration that there is no systematic procedure which can distinguish between algorithms (programs that always work) and programs that do not always work.
% \end{quote}

% Een belangrijke theorema stelt dat fout onmogelijk constant kan zijn:
% \begin{theorem}
% Voor geen enkele heuristiek bestaat geen getal $E$ waarvoor geldt:
% \begin{quote}
% dat voor elke probleem-instantie van het probleem, $\fun{f}{\xdot}-\fun{f}{L}\leq L$.
% \end{quote}
% \end{theorem}


\section{Metaheuristieken}

\subsection{Problemen met heuristieken}

Heuristieken bieden een antwoord door een algoritme uit te voeren die in polynomiale tijd een oplossing zal uitrekenen. In het geval het algoritme snel genoeg is, en we kunnen leven met de garanties die dit algoritme biedt, is dit een acceptabele methode. In de meeste gevallen is dit echter niet zo. Praktische problemen zijn groot en complex en doorgaans kan een heuristiek weinig garanties bieden. Een ander probleem met heuristieken is dat ze weinig aanpasbaar zijn: stel dat we een bepaalde tijd ter beschikking stellen, dan zal het algoritme zich doorgaans niet aan deze beperking houden: ofwel loopt het algoritme eerder af en maakt het dus geen gebruik van alle beschikbare rekentijd, indien het algoritme niet afloopt binnen de gespecificeerde tijd is er ook geen sprake van een parti\"ele oplossing.

\subsection{Formele definitie}

Metaheuristieken proberen deze problemen op te lossen. We geven eerst een formele definitie van een metaheuristiek waarna we relevante terminologie invoeren.

\begin{definition}[Metaheuristiek]
\deflab{metaheuristic}
Een metaheuristiek is een algoritme die een oplossingsruimte $\SolSet\subseteq\accl{\sol|\forall \sol\in \ConfigSet:\fun{\hcfun}{\sol}}\subseteq\ConfigSet$ beschouwd met $\bestSol\in\SolSet$. Verder beschouwd het \'e\'en of meer overgangsfuncties $h_i:\SolSet^{k_i}\times\RealSet^{l_i}\rightarrow\SolSet$. De metaheuristiek werkt door \'e\'en of meerdere instanties $s_1,s_2,\ldots,s_j$ uit $\SolSet$ te genereren. En vervolgens herhaaldelijk deze overgangsfuncties toe te passen op deze instanties. De resultaten van deze functietoepassingen kun gebruikt worden in andere toepassingen van de overgangsfuncties. Het algoritme stopt wanneer aan een bepaalde stopconditie voldaan is (bijvoorbeeld: het algoritme draait een bepaalde tijd op de machine). Hierna wordt de oplossing met de beste fitness-waarde als uitvoer teruggegeven.
\end{definition}

Op basis van deze definitie kunnen we ook een algoritme op hoog niveau opstellen zoals beschreven in \algref{metaheuristicGeneral}.

\begin{algorithm}[H]
 \SetAlgoLined
 Bereken een initi\"ele set van oplossingen $\PopSet_1$ en hun fitness-waarde\;
 $b_1\leftarrow\displaystyle\argmin_{\sol\in\PopSet_1}{\fun{\evalfun}{\sol}}$\;
 \Repeat{het stopcriterium is bereikt}{
  Genereer op basis van $\PopSet_t$ en $t$ stochastisch een nieuwe set oplossingen $\PopSet_{t+1}$ samen met hun fitness-waarde\;
  $b_{t+1}\leftarrow\displaystyle\argmin_{\sol\in\PopSet_{t+1}\cup\accl{b_t}}{\fun{\evalfun}{\sol}}$\;
  $t\leftarrow t+1$\;
 }
 \KwRet{$b_t$}
 \caption{Hoog niveau beschrijving van een metaheuristiek\cite{DBLP:journals/jc/ShonkwilerV94}.}
 \alglab{metaheuristicGeneral}
\end{algorithm}

Typisch aan metaheuristieken is een (sterke) aanwezigheid van toevalsgetallen. Zo hebben we bij de signatuur van de overgangsfuncties ook een set re\"ele getallen opgenomen. Deze getallen worden door het toeval gegenereerd en bepalen mee het resultaat van de functie. Een belangrijk concept die we hiermee kunnen introduceren is de \emph{omgeving} ofwel ``\emph{neighborhood}'' van een overgangsfunctie:

\begin{definition}[Omgeving van een overgangsfunctie]
De omgeving van een overgangsfunctie is de verzameling van alle oplossingen die we kunnen genereren vanuit een gegeven set van oplossingen ongeacht de waarde van de toevalsfactoren. De omgeving van een functie $h_i$ is dus:
\begin{equation}
\fun{\neighbr_{h_i}}{s_1,s_2,\ldots,s_{k_i}}=\accl{s|s=\fun{h_i}{s_1,s_2,\ldots,s_{k_i},\xi_1,\xi_2,\ldots,\xi_{l_i}}}
\end{equation}
\end{definition}

\subsubsection{Local Search}
Het concept van een omgeving is belangrijke omdat het meteen ook een populaire zoekstrategie voor metaheuristieken introduceert: \emph{lokaal zoeken} ofwel ``\emph{local search (LS)}''. Deze zoekstrategie vertrekt van een gegeven oplossing en zoekt - volgens een bepaalde omgeving - alle oplossingen in de buurt af op zoek naar een betere oplossing. In het geval we zo'n oplossing vinden wordt deze oplossing de nieuwe oplossing en beginnen we vervolgens een zoektocht rond de nieuwe oplossing. Local Search komt voor in twee smaken: ``\emph{first-improvement}'' en ``\emph{best-improvement}''. In het geval van \emph{first-improvement} wordt de eerste oplossing die beter is dan de huidige oplossing de nieuwe actieve oplossing. In het geval van \emph{best-improvement} doorzoeken we de volledige omgeving en migreren we naar de beste oplossing in de omgeving.
\paragraph{}
Local Search is een krachtige optimalisatietechniek die doorgaans tot acceptabele resultaten kan leiden. Het probleem zit hem in het idempotente karakter van local search: \'e\'enmaal we local search op een oplossing hebben toegepast heeft een tweede maal local search toepassen met dezelfde omgevings-definitie geen zin: we weten immers dat er in de omgeving geen betere oplossingen gevonden zullen worden want anders was het algoritme de vorige keer niet bij deze oplossing gestopt. Omwille van deze reden kan local search zelf geen volwaardige metaheuristiek worden genoemd\cite{lsAndMh}. We verwachten immers dat als we meer tijd investeren, we op termijn altijd tot betere resultaten $\xdot$ ofwel de echte oplossing $\xstar$ zullen komen. Local search vormt echter de basis voor een groot aantal metaheuristieken die doorgaans een mechanisme implementeren om de oplossing uit het lokaal optimum te laten migreren.

\subsection{De ``Zoo van de Metaheuristieken''}

\defref{metaheuristic} is vrij abstract. Daarom zullen we in deze sectie de belangrijkste families van metaheuristieken kort beschouwen.

\subsubsection{Genetische Algoritmes}

\emph{Genetische algoritmen} ofwel ``\emph{Genetic Algorithms (GA)}'' zijn de eerste familie van metaheuristieken en werken op basis van een populatie: een set van oplossingen. Uit deze populatie worden twee of meer oplossingen geselecteerd. De selectie is meestal gerelateerd aan de fitness-waarde van deze oplossingen. Vervolgens past men een recombinatie-operator toe: een overgangsfunctie die twee of meer oplossingen als invoer neemt en op basis hiervan een nieuwe oplossing genereert die eigenschappen van alle ouders deelt. Doorgaans past men op deze oplossing ook een mutatie toe: men zal de oplossing lichtjes aanpassen door middel van een andere overgangsfunctie. Vervolgens de oplossing onder bepaalde voorwaarden in de populatie ge\"injecteerd. In ruil voor de nieuwe oplossing zal de populatie ook \'e\'en of meer oplossingen uit de populatie verwijderen.

\subsubsection{Simulated Annealing}

\emph{Simulated Annealing (SA)} is de eerste gepubliceerde metaheuristiek. Het is een schema gebaseerd op het \algo{Algoritme van Metropolis}. Het werkt aan de hand van \'e\'en overgangsfunctie en \'e\'en oplossing die soms de actieve oplossing wordt genoemd. Het algoritme voert telkens de overgangsfunctie uit op de actieve oplossing. De resulterende oplossing beschouwen we als de nieuwe oplossing met een kans:
\begin{equation}
\fun{p}{\mbox{accept $s_1\rightarrow s_2$}}=\fun{\min}{1,e^{\brak{\fun{\evalfun}{s_2}-\fun{\evalfun}{s_1}}/T}}
\end{equation}

Deze formule stelt dat indien de nieuwe oplossing beter is dan de oude oplossing, we altijd accepteren. Indien de nieuwe oplossing minder gunstig is accepteren we met een bepaalde kans die kleiner wordt naarmate het verschil in fitness-waarde groeit. In de formule staat ook een onbekende parameter $T$ ofwel \emph{temperatuur}. De temperatuur bepaalt hoe sterk de kans daalt naarmate de kloof groeit. Het is een variabele die initieel op een positief getal wordt gezet en gedurende het zoekproces langzaam naar 0 zakt. Dit betekent dat we in het begin sterk geneigd zijn om een slechtere oplossing te accepteren. Op het einde accepteren we bijna uitsluitend oplossing die beter zijn dan hun ouder. Hoe de temperatuur concreet evolueert kan vrij ingesteld worden en introduceert dan ook een groot aantal varianten.

\subsubsection{Iterated Local Search}

In de vorige sectie bespraken we \emph{Local Search}. Het probleem met \emph{Local Search} is echter dat het convergeert naar een lokaal minimum en vanaf dat moment geen vooruitgang meer kan maken. \emph{Iterated Local Search (ILS)} is een zoekproces dat afwisselt tussen twee fases: in de \emph{local search}-fase optimaliseert het programma de oplossing tot het in een lokaal optimum terecht komt; in de \emph{perturbatie}-fase voert men een overgangsfunctie uit die met een zekere kans in staat moet zijn om een oplossing te genereren die uit het lokale optimum ontsnapt.

\subsubsection{Variable Neighbourhood Search}

\emph{Variable Neighbourhood Search (VNS)} is een metaheuristiek die verder bouwt op \emph{Iterated Local Search}. In het geval van \emph{Variable Neighbourhood Search} is er echter sprake van verschillende definities voor een omgeving $\neighbr_i$ in een iteratie zullen in de \emph{shake}-fase migreren naar een random oplossing in de omgeving $\neighbr_i$ en vervolgens passen we \emph{local search} toe op basis van deze omgeving. In het geval we tot een betere oplossing komen, wordt de eerste omgeving $\neighbr_1$ opnieuw de actieve omgeving. In het andere geval kiezen we de volgende omgeving $\neighbr_{i+1}$. Op het moment dat alle omgevingen zijn uitgeput beginnen we ook opnieuw bij $\neighbr_1$.%in het geval we een lokaal optimum volgens omgeving $\calN_i$ bereiken, zullen we \emph{local search} toepassen op basis van de volgende omgeving $\calN_i$ in de hoop dat deze omgeving ons naar een betere oplossing zal leiden. In het geval alle

\subsubsection{Tabu Search}
In het geval van \emph{Tabu Search} is de omgeving de unie van een reeks deelomgevingen. Onder bepaalde voorwaarden kan men beslissen een deel van de omgeving of oplossingsruimte tijdelijk ontoegankelijk te verklaren. De acties of locaties vallen op dat moment onder ``\emph{tabu}''. Dit kan bijvoorbeeld nuttig zijn om eerdere acties niet plots ongedaan te maken. Acties of oplossingsruimtes vallen maar tijdelijk onder tabu: na een aantal iteraties worden de elementen weer toegankelijk.

%\subsection{Classificatie in de ``Zoo van de Metaheuristieken''}

\subsection{Omzetten van beperkingen naar evaluaties}

Soms is $c$ een complexe functie met een weinig voorspelbaar gedrag. Dit heeft een implicatie op de transitiefuncties die doorgaans veel rekenkracht nodig hebben om een oplossing te genereren die aan de harde beperkingen voldoet.

\paragraph{}
Een oplossing voor dit probleem is het omzetten van een deel de harde beperkingen $c$ in de evaluatiefunctie $f$. Oplossingen die niet aan een deel van de harde beperkingen voldoen, zullen we toch als geldige oplossingen aanzien, maar met een hoge fitness-waarde. De procedure die berekend welke oplossing wordt ook aangepast zodat enkel een geldige oplossing kan worden teruggegeven. Een algoritme die een optimalisatieprobleem $\tupl{X,c_1\wedge c_2,f}$ oplost, kan dus inwendig een optimalisatieprobleem $\tupl{X,c_1,f-K\cdot\krdelta{c_2}}$ oplossen met $K$ een grote constante.

\subsection{Modelleren van Metaheuristieken}

Elke metaheuristiek die we hierboven beschreven hebben dient telkens drie belangrijke vragen in het achterhoofd te houden\cite{DBLP:journals/jc/ShonkwilerV94}:
\begin{enumerate}
 \item kan het globale optimum altijd gevonden worden door de metaheuristiek,
 \item hoe kunnen we identificeren dat we het globale optimum gevonden hebben, en
 \item hoe lang zal het duren alvorens we dit optimum gevonden hebben
\end{enumerate}

Wanneer we geen details kennen in verband met de vorm van de evaluatiefunctie $\evalfun$ spreekt het voor zich dat we enkel zeker kunnen zijn dat we een globaal optimum hebben gevonden door middel van \emph{exhaustive search}. Ook wat betreft de derde vraag verwachten we een \emph{exhaustive search} proces alvorens we zeker zijn dat we het optimum hebben gevonden. De verwachtte tijd alvorens dit gebeurt kan echter sterk verschillen van de tijd die we dienen te besteden aan het doorzoeken van een significant deel van de zoekruimte. Berekenen wanneer we gemiddeld dit optimum zullen bereiken staat bekend als het \prbm{Hitting Time Problem}. Om dit probleem te formaliseren dienen we eerst de notie van de raaktijd van een Markov-keten te defini\"eren:

\begin{definition}[Raaktijd $\hittime$]
We defini\"eren de raaktijd $\hittime$ van een Markov-keten $\PopChain$ die bestaat uit populaties $\PopSet_t$ als:
\begin{equation}
\fun{\hittime}{\PopChain}=\min\accl{t|\PopSet_t\in\PopChain\wedge\ConfigOpSet\cap \PopSet_t\neq\emptyset}
\end{equation}
We kunnen deze definitie ook uitbreiden naar de raaktijd voor een zekere fitness-waarde $v$:
\begin{equation}
\fun{\hittime}{\PopChain,v}=\min\accl{t|\PopSet_t\in\PopChain:\exists \sol\in \PopSet_t:\fun{\evalfun}{\sol}\leq v}
\end{equation}
\end{definition}

Het \prbm{Hitting Time Problem} gaat vervolgens op zoek naar de raaktijd van een gemiddelde Markov-keten.

\subsubsection{Verwachtte tijd van een sequentieel proces}

Op basis van \algref{metaheuristicGeneral} kunnen we uitspraken doen, zowel over de verwachtte raaktijd wanneer we het zoeken uitbesteden aan \'e\'en processor of uitbesteden aan verschillende processoren die elk onafhankelijk een eigen zoekproces laten lopen. Onderzoek naar de raaktijd is gepubliceerd in \cite{DBLP:journals/jc/ShonkwilerV94}. Hiervoor zal men een Markov-model beschouwen. De knopen van dit Markov-model stellen populaties voor: een verzameling van oplossingen. We kunnen hier dus denken aan een verzameling $\PopSet_i$ in \algref{metaheuristicGeneral}. Als beperking stellen we dat de populatie een vaste grootte heeft. Deze beperking is redelijk vermits elke praktische machine een eindig geheugen heeft en dus ook maar een eindig aantal oplossingen tegelijk kan beschouwen. Verder bevat ons Markov-model ook overgangskansen $\fun{p}{t,i,j}$: de kans om van een populatie $\PopSet_i$ naar een populatie $\PopSet_j$ te gaan op tijdstip $t$. Indien de waarde van $\fun{p}{i,j,t}$ constant blijft over de tijd $t$ dan spreken we over een \emph{stationair} proces (dit is typisch voor bijvoorbeeld een genetisch algoritme), indien de kansen in de tijd veranderen beschouwen we een \emph{niet-stationair} proces.

\paragraph{}

Indien een populatie een oplossing bevat met een fitness-waarde die kleiner of gelijk is aan de waarde die we zoeken $v$, spreken we over een \emph{doel-populatie}, in het andere geval zullen we spreken over een \emph{normale populatie}. We kunnen zonder verlies van algemeenheid de populaties zo ordenen dat de populaties $\PopSet_1,\PopSet_2,\ldots,\PopSet_g$ doel-populaties zijn, en de populaties $\PopSet_{g+1},\PopSet_{g+2},\ldots,\PopSet_N$ populaties waar er geen gewenste oplossing in zit. In dat geval kunnen we de transitiematrix $P$ opdelen in submatrices:
\begin{equation}
P=\brak{\begin{array}{cc}
J&H\\
B&\hat{P}
\end{array}}
\end{equation}
Hierbij stelt $J$ een $g\times g$ voor, $H$ een $g\times N-g$, $B$ een $N-g\times g$ matrix en $\hat{P}$ logischerwijs een $N-g\times N-g$ matrix. Het spreekt voor zich dat de waarde van $J$ en $H$ niet zo interessant zijn: eenmaal we ons in een doel-populatie bevinden kunnen we immers stoppen met het algoritme uit te voeren. Daarom zullen we stellen dat $J=\identitymatrix[g\times g]$ en $H=\zeromatrix[g\times N-g]$. We streven er verder naar om met ons algoritme de waardes in $B$ -- ook wel de \emph{bridge} genoemd -- zo hoog mogelijk te maken: deze matrix bevat immers de kansen om van naar een doel-populatie te migreren. $\hat{P}$ wordt ook wel de \emph{verwijderde transitiematrix} genoemd. De waardes in de matrix worden be\"invloed door het probleem (via de definities van de omgevingen) en het zoekalgoritme (de metaheuristiek in kwestie).
\paragraph{}
De kwaliteit van een zoekmethode na $t$ stappen kunnen we uitdrukken met een probabiliteitsvector $\vec{\alpha}_t$. $\alpha_{t,i}$ geeft aan met hoeveel kans het algoritme in tijdstap $t$ de populatie $\PopSet_i$ beschouwt. Net als bij de matrix delen we de probabiliteitsvector op in twee delen: een gedeelte $\vec{\alpha}^G_t$ met dimensie $g$ en een gedeelte $\vec{\hat{\alpha}}_t$. Op basis van de transitiematrix kunnen we de probabiliteitsvector na $t$ stappen berekenen in functie van $\alpha_0$:
\begin{equation}
\vec{\alpha}_t=\brak{\vec{\alpha}_t^G\ |\ \vec{\hat{\alpha}}_t}=\vec{\alpha}_{t-1}\cdot P=\brak{\vec{\alpha}_{t-1}^G+B\cdot\vec{\hat{\alpha}}_{t-1}\ |\ \vec{\hat{\alpha}}_{t-1}\cdot\hat{P}}
\eqnlab{oneStepTransition}
\end{equation}
We zijn vooral ge\"interesseerd in de fractie van Markov-ketens die in stap $t$ naar een doel-populatie migreren ofwel de kans dat we stap $t$ een gewenste oplossing bereiken:
\begin{equation}
\Prob{\theta=t}=\displaystyle\sum_{i=g+1}^{N}\brak{\alpha_{t-1,i}\cdot\displaystyle\sum_{j=1}^{g}\fun{p}{t,i,j}}=\vec{\hat{\alpha}}_{t-1}\cdot B\cdot\onematrix[1\times N-g]
\eqnlab{exhaust}
\end{equation}
Een ander logische gevolg uit \eqnref{oneStepTransition} zijn de transities van normale populaties naar andere normale populaties. De som van de kansen die in deze deelvector aanwezig zijn, is de kans dat we na deze $t$ stappen nog steeds geen acceptabele oplossing gevonden hebben:
\begin{eqnarray}
\vec{\hat{\alpha}}_t=\vec{\hat{\alpha}}_{t-1}\cdot\hat{P}=\vec{\hat{\alpha}}_{t-2}\cdot\hat{P}^2=\ldots=\vec{\hat{\alpha}}_{0}\cdot\hat{P}^t\eqnlab{remainder}\\
\Prob{\theta>t}=\displaystyle\sum_{i=g+1}^{N}\alpha_{t,i}=\vec{\hat{\alpha}}_t\cdot\onematrix[1\times N-g]=\vec{\hat{\alpha}}_{0}\cdot\hat{P}^t\cdot\onematrix[1\times N-g]\eqnlab{nothit}
\end{eqnarray}
Op basis van \eqnref{remainder} en \eqnref{nothit} kunnen we nu de verwachte stap berekenen waarop we een gewenste oplossing zullen berekenen:
\begin{equation}
\mean{\theta}=1+\displaystyle\sum_{i=0}^{\infty}{\Prob{\theta>i}}=1+\displaystyle\sum_{i=0}^{\infty}{\vec{\hat{\alpha}}_{0}\cdot\hat{P}^i\cdot\onematrix[1\times N-g]}
\eqnlab{meanHit}
\end{equation}
In deze vergelijking tellen we elke kans $\Prob{\theta=k}$ juist $k$ keer.
\paragraph{}
Vermits $\hat{P}$ een matrix met kansen voorstelt is elke element $\hat{p}_{i,j}\geq 0$. We maken verder de assumptie dat we na een arbitrair aantal stappen $m$, vanuit elke normale populatie $\calP_i$ een kans bestaat dat we naar een andere normale populatie $\calP_j$ kunnen migreren. Vermits hierdoor de matrix primitief is, en er minstens \'e\'en rij van $\hat{P}$ niet sommeert naar 1 (anders zouden we nooit in een doel-populatie kunnen terechtkomen), weten we dat de grootste eigenwaarde $\ev[\hat{P}]<1$.

% Een theorema stelt:
% \begin{theorem}
% stel de twee grootste eigenwaardes $\lambda_1>\abs{\lambda_2}$ van een $n\times n$ matrix $A$. Dan bestaat er een vaste veelterm $h$ met een graad $0\leq\funm{deg}{h}< n-1$ zodat:
% \begin{equation}
% \forall k=1,2,\ldots:\abs{\displaystyle\frac{\vec{x}\cdot A\cdot\onematrix[1\times n]}{\lambda_1^k}-\vec{x}\cdot\vec{v}}<\fun{h}{k}\cdot\abs{\displaystyle\frac{\lambda_2}{\lambda_1}}^k
% \end{equation}
% Met $\vec{x}$ een willekeurige vector en $\vec{v}$ de rechtse eigenvector van $\lambda_1$.
% \thelab{eigenValuesMatrix}
% \end{theorem}
\paragraph{}
We kunnen een eigenvector benaderen door een $\onematrix$-vector een groot aantal maal toe te passen op de matrix in kwestie en vervolgens te normaliseren. Daarom kunnen we stellen dat voor een grote $t$:
\begin{equation}
\begin{array}{cc}
\vec{x}\cdot\hat{P}^t\cdot\onematrix[1\times N-g]\approx\vec{x}\cdot\ev[1,\hat{P}]^t\cdot\evr[\hat{P}]=\ev[1,\hat{P}]^t\cdot\sigma&\mbox{($t\gg 1$)}
\end{array}
\eqnlab{longTermAlpha}
\end{equation}
Wanneer we als $\vec{x}$ de begindistributie $\vec{\hat{\alpha}}_0$ nemen, kunnen we het dot-product tussen $\vec{\hat{\alpha}}_0$ en $\evr[\hat{P}]$ defini\"eren als $\sigma$. We kunnen vervolgens \eqnref{meanHit} en \eqnref{longTermAlpha} samennemen in een nieuwe vergelijking die
%ons met behulp van \theref{eigenValuesMatrix}
een benaderende waarde voor de gemiddelde raaktijd oplevert:
\begin{equation}
\mean{\theta}\approx 1+\vec{\hat{\alpha}}_0\cdot\onematrix+\sigma\cdot\brak{\displaystyle\sum_{i=1}^{\infty}\lambda_{1,\hat{P}}^i}=1+\vec{\hat{\alpha}}_0\cdot\onematrix+\displaystyle\frac{\sigma\cdot \lambda_{1,\hat{P}}}{1-\lambda_{1,\hat{P}}}
\end{equation}
Net zoals we de termen van dit gemiddelde benadert hebben aan de hand van \eqnref{longTermAlpha}, kunnen we de eerste termen benaderen door deze vergelijking omgekeerd toe te passen. We stellen dus dat $1+\vec{\hat{\alpha}}_0\cdot\onematrix=\sigma\cdot\brak{1+\lambda^{-1}}$. Dit levert ons een ruwe schatting voor de raaktijd op:
\begin{equation}
\mean{\hittime}\approx\displaystyle\frac{\sigma}{\brak{1-\lambda_{1,\hat{P}}}\cdot\lambda_{1,\hat{P}}}
\eqnlab{hitTimeSingle}
\end{equation}

\subsubsection{Onafhankelijke parallelle Monte-Carlo simulaties}

\cite{DBLP:journals/jc/ShonkwilerV94} toont ook een logische stap tot parallellisatie: $p$ processoren draaien elk onafhankelijk van elkaar een Monte-Carlo simulatie. We kunnen dit fenomeen modelleren met behulp van een Markov-keten waarbij elke knoop van de keten een $p$-tuple voorstelt met de populaties van de verschillende processoren in de tijdstap. Vervolgens defini\"eren we \emph{parallelle raaktijd} $\phittime$ als volgt:

\begin{definition}[Parallelle raaktijd $\phittime$]
We defini\"eren de parallelle raaktijd $\phittime$ van een Markov-keten $\PopChain$ die bestaat uit $p$-tuples van populaties $\tupl{\PopSet_{t,1},\PopSet_{t,2},\ldots,\PopSet_{t,p}}$ als:
\begin{equation}
\fun{\phittime}{\PopChain}=\min\accl{t|\tupl{\PopSet_{t,1},\PopSet_{t,2},\ldots,\PopSet_{t,p}}\in\PopChain\wedge\exists i:\ConfigOpSet\cap \PopSet_{t,i}\neq\emptyset}
\end{equation}
We kunnen deze definitie ook uitbreiden naar de raaktijd voor een zekere fitness-waarde $v$:
\begin{equation}
\fun{\phittime}{\PopChain,v}=\min\accl{t|\tupl{\PopSet_{t,1},\PopSet_{t,2},\ldots,\PopSet_{t,p}}\in\PopChain\wedge\exists i\exists \sol\in\PopSet_{t,i}:\fun{\evalfun}{\sol}\leq v}
\end{equation}
\end{definition}
Vermits de verschillende processoren een onafhankelijk en equivalent proces uitvoeren, kunnen we gebruik maken van het theorema van de onafhankelijke kansen met de onafhankelijke EN-regel:
\begin{equation}
\begin{aligned}
\Prob{\phittime\geq t}&=\Prob{\hittime_1\geq t\wedge\hittime_2\geq t\wedge\ldots\wedge\hittime_p\geq t}\\
&=\Prob{\hittime_1\geq t}\cdot\Prob{\hittime_2\geq t}\cdot\ldots\cdot\Prob{\hittime_p\geq t}\\
&=\Prob{\hittime\geq t}\cdot\Prob{\hittime\geq t}\cdot\ldots\cdot\Prob{\hittime\geq t}=\Prob{\hittime\geq t}^p
\end{aligned}
\eqnlab{probabilityPower}
\end{equation}
Op basis van deze regel kunnen we de gemiddelde parallelle raaktijd bepalen op basis van \eqnref{meanHit}:
\begin{equation}
\begin{aligned}
\mean{\phittime}&=1+\displaystyle\sum_{i=0}^{\infty}{\Prob{\phittime>i}}=1+\displaystyle\sum_{i=0}^{\infty}{\Prob{\hittime>i}^p}\\
&\approx 1+\brak{\vec{\hat{\alpha}}_0\cdot\onematrix}^p+\sigma^p\cdot\brak{\displaystyle\sum_{i=1}^{\infty}\lambda_{1,\hat{P}}^{p\cdot i}}=1+\brak{\vec{\hat{\alpha}}_0\cdot\onematrix}^p+\displaystyle\frac{\sigma^p\cdot\lambda_{1,\hat{P}}^p}{1-\lambda_{1,\hat{P}}^p}\\
&\approx\displaystyle\frac{\sigma^p}{\brak{1-\lambda_{1,\hat{P}}^p}\cdot\lambda_{1,\hat{P}}^{p}}
\end{aligned}
\eqnlab{probabilityPower}
\end{equation}
De \emph{speed-up} is bijgevolg gelijk aan:
\begin{equation}
\funm{speed-up}{p}=\displaystyle\frac{\mean{\hittime}}{\mean{\phittime}}=\displaystyle\frac{\lambda_{1,\hat{P}}^{p-1}}{\sigma^{p-1}}\cdot\displaystyle\frac{1-\lambda_{1,\hat{P}}^{p}}{1-\lambda_{1,\hat{P}}}\approx\displaystyle\frac{p\cdot\lambda^{p-1}}{\sigma^{p-1}}
\eqnlab{speedupMetaheuristic}
\end{equation}
In het laatste deel van de vergelijking vervangen we ook $\ev[\hat{P}]$ door $\lambda$. Dit is louter om de formules die hiervan afgeleid zijn leesbaar te houden.

\subsubsection{Semantiek van parameters $\sigma$ en $\lambda$}

\eqnref{speedupMetaheuristic} formaliseert de verwachte \emph{speed-up} bij een probleem. Deze formule bevat 3 parameters en kan daarom niet zomaar ge\"interpreteerd worden. Behalve het aantal parameters $p$ is het niet triviaal om de overige parameters te interpreteren.

\paragraph{}
We hebben in \eqnref{longTermAlpha} een benadering geformuleerd voor de distributie over normale populaties. Elke initi\"ele distributie zal bijgevolg altijd convergeren naar een distributie proportioneel aan de sterkste linkse eigenvector $\evl[\hat{P}]$. Eenmaal $\vec{\hat{\alpha}}_t\approx\evl[\hat{P}]$ kunnen we stellen dat:
\begin{equation}
\conditional{\vec{\hat{\alpha}}_{t+1}=\vec{\hat{\alpha}}_t\cdot\hat{P}=\lambda\cdot\vec{\hat{\alpha}}_{t}}{$t\gg 1$}
\end{equation}
Bijgevolg kunnen we $\lambda$ interpreteren als de kans op lange termijn dat we vanuit een normale populatie de volgende stap niet naar een doel-populatie migreren. Voor elk zinvol probleem kunnen we stellen dat $\lambda$ dicht bij $N-g/N\approx 1$ zal blijven (dit is ook de oorzaak van de laatste vereenvoudiging in \eqnref{speedupMetaheuristic}). Verder geldt altijd: $0\leq\lambda<1$.

\paragraph{}

We kunnen ook de rechtse dominante eigenvector $\evr[\hat{P}]$ beschouwen. Vermits eigenvectoren geen karakteristieke lengte hebben, beschouwen we $\dabs[1]{\evr[\hat{P}]}=1$. Vermits het volgende geldt:
\begin{equation}
\conditional{A^t\approx\ev[A]^t\cdot\evr[A]\cdot\evl[A]^T}{$t\gg1$}
\end{equation}
Kunnen we stellen dat de genormaliseerde rechtse eigenvector een probabiliteitsvector is die aangeeft in welke mate populaties $i$ bijdragen tot het behoudt in een normale populatie. Wanneer we dus de $i$-de gewone populatie beschouwen en het $i$-de element van $\evr[\hat{P}]$ is klein, is er een grote kans dat we in een doel-toestand terecht zullen komen.

\paragraph{}

De interpretatie van de rechtse eigenvector vormt de basis voor de interpretatie van $\sigma$. Vermits $\sigma$ het dot-product is tussen de probabiliteitsvector $\vec{\hat{\alpha}}_0$ en $\evr[\hat{P}]$. Dit dot-product is proportioneel met de cosinus van de hoek tussen beide vectoren:
\begin{equation}
\fun{\cos}{\vec{\hat{\alpha}}_0,\evr[\hat{P}]}=\displaystyle\frac{\vec{\hat{\alpha}}_0^T\cdot\evr[\hat{P}]}{\dabs{\vec{\hat{\alpha}}_0}\cdot\dabs{\evr[\hat{P}]}}=\displaystyle\frac{\sigma}{\dabs{\vec{\hat{\alpha}}_0}\cdot\dabs{\evr[\hat{P}]}}
\end{equation}
Uit de definitie van de cosinus kunnen we bovendien stellen dat:
\begin{equation}
\dabs{\evr[\hat{P}]}=\displaystyle\frac{\dabs{\evl[\hat{P}]}}{\fun{\cos}{\evl[\hat{P}],\evr[\hat{P}]}}
\end{equation}
Bijgevolg kunnen we stellen dat:
\begin{equation}
\sigma=\displaystyle\frac{\dabs{\hat{\alpha}_0}\cdot\fun{\cos}{\vec{\hat{\alpha}}_0,\evr[\hat{P}]}}{\dabs{\evl[\hat{P}]}\cdot\fun{\cos}{\evl[\hat{P}],\evr[\hat{P}]}}
\eqnlab{sigmaMeaning}
\end{equation}
We kunnen dus stellen dat $\sigma$ de ratio is tussen de projecties van enerzijds de initi\"ele kansverdeling $\vec{\hat{\alpha}}$ en anderzijds de linkse eigenvector $\evl[\hat{P}]$ op de rechtse eigenvectoren $\evr[\hat{P}]$. Wanneer $\sigma$ klein is verwachten we sneller een oplossing te vinden. De factoren die hiertoe bijdragen zijn dus:
\begin{itemize}
 \item Een kleine $\dabs{\vec{\hat{\alpha}}_0}$. Vermits de som van $\vec{\hat{\alpha}}_0$ neerkomt om de kans dat onze beginpopulatie geen doelpopulatie is, streven we er naar om deze zo laag mogelijk te houden.
 \item Wanneer $\vec{\hat{\alpha}}_0$ en $\evr[\hat{P}]$ niet gelijkaardig zijn, dan zijn de populaties waar we met een grote kans in starten niet de populaties die met een grote kans naar een normale populatie migreren in de volgende stap. Wanneer de cosinus tussen de vectoren dus klein is, verwachten we in de eerste stappen naar een doel-populatie te migreren.
 \item Wanneer de linkse en de rechtse eigenvector gelijk zijn, is de matrix $\hat{P}$ symmetrisch. Indien de matrix symmetrisch is, verwachtten we doorgaans minder populaties waarnaar we kunnen migreren, maar vervolgens niet uit kunnen geraken. Indien de matrix immers symmetrisch is, is de kans om vanuit een populatie in een andere populatie te migreren immers dezelfde om er vervolgens terug uit te geraken. Daarom streven we naar een zo minimaal mogelijk hoek tussen de twee.
\end{itemize}
Uit de formule kunnen we afleiden dan $\sigma$ aan slechts \'e\'en kant begrensd is: $0<\sigma$.

\subsubsection{Superlineaire Speed-up}

Vermits $0\leq\lambda<1$ en $0<\sigma$, kunnen we met behulp van \eqnref{speedupMetaheuristic} bepalen welke versnelling mogelijk is. Dit is mogelijk wanneer $\sigma<\lambda$. Een opmerkelijk feit is dat deze grenzen superlineaire speed-up niet uitsluiten. Sterker nog, \cite{DBLP:journals/jc/ShonkwilerV94} ontwikkelen in hun paper enkele metaheuristieken voor problemen waar men ook effectief superlineaire speed-up kan vaststellen.

\paragraph{}

Superlineaire speed-up zorgt echter in de literatuur voor veel ophef\cite{superlinearSpeedup}. Theoretisch kan men immers een parallel proces op een sequenti\"ele processor emuleren. Deze processor voert dan afwisselend het werk uit van \'e\'en van de kernen. In de praktijk neemt men soms superlineaire speed-up waar en dit zelfs op een consistente manier. Doorgaans wijt men dit echter aan het \emph{cache-effect}: als we een algoritme op verschillende processoren uitvoeren beschikken we ook over meer snelle geheugens (\emph{cache}). Bovendien kan een deel van het verwerken van data soms uitbesteed worden aan de netwerkapparatuur (bijvoorbeeld bepalen welke processoren op de hoogte moeten worden gebracht van een bepaalde gebeurtenis). Vermits we echter in bovenstaande redenering abstractie van deze extra bronnen van speed-up kan dit de oorzaak niet zijn.

\paragraph{}

De anomalie zit dan ook waarschijnlijk in het feit dat de parallelle variant van de Monte-Carlo simulatie geen zuivere metaheuristiek is: wanneer we immers het aantal processoren opdrijven, drijven we ook het aantal initi\"ele populaties op. Zoals we uit \eqnref{sigmaMeaning} kunnen afleiden wordt $\sigma$ klein indien de beginverdeling $\vec{\hat{\alpha}}$ klein is of sterk afwijkt van $\evr[\hat{P}]$. In dat geval loont het dus eerder de moeite van telkens nieuwe populaties te genereren dan deze populaties te laten evolueren. We kunnen dus stellen dat in het geval $\sigma<\lambda$, de metaheuristiek eenvoudigweg slecht is opgesteld. De voorbeelden die \cite{DBLP:journals/jc/ShonkwilerV94} aanhaalt zijn dan ook problemen in \comp{P} of de metaheuristieken zijn niet correct afgesteld (bijvoorbeeld te lokaal) op het probleem.

\subsubsection{A flaw in the plan: anomalie\"en in het model}

Het voorgestelde model vertoond enkele anomalie\"en. Hieronder geven we een bondig overzicht.

\paragraph{}
We hebben een stationair Markov-systeem gemodelleerd. Metaheuristieken hebben eerder een dynamisch karakter: op basis van kennis uit het verleden, veranderen de transitiematrices per tijdstap. In het geval van bijvoorbeeld \emph{Simulated Annealing} gebeurt dit volgens een vast patroon en kunnen we sommige effecten modelleren. Meestal echter veranderen de kansen op basis van de bezochte populaties. In dat geval is het minder evident om een model op te stellen.

\paragraph{}
In het model vraagt het genereren van een populatie dezelfde hoeveelheid tijd als een transitie. In de praktijk verwachten we dat in heel wat gevallen de tweede stap sneller zal verlopen (omdat de configuraties en populaties maar gedeeltelijk aangepast zullen worden). Dit is ook een aspect die pleit voor metaheuristieken: we besparen tijd door de transities sneller uit te voeren dan het genereren van nieuwe configuraties.

\paragraph{}
Niet elke transitie verloopt even snel: sommige transities vragen inherent meer tijd omdat bijvoorbeeld een groter deel van de populatie wordt aangepast of er veranderen meer variabelen in een configuratie van waarde. Vermits het programma draait op een processor die maar een eindig aantal bits in constante tijd kan veranderen\footnote{We beschouwen geen vector computer.} zullen sommige transities meer tijd kosten.

\paragraph{}
De meeste metaheuristieken de voorkeur aan migratie naar sterke populaties. Hiervoor worden algoritmes zoals Local Search gebruikt. Het spreekt voor zich dat local search transities meestal meer tijd kosten omdat de evaluatiefuncties onderweg voortdurend moeten worden uitgerekend. We kunnen dit probleem oplossen door het introduceren van dummy-populaties: populaties die de toestanden onderweg voorstellen en zo dus meer tijdstappen genereren. Het is echter minder evident om de parameters $\sigma$ en $\lambda$ te berekenen.

\subsubsection{Minimale Speed-up}

Metaheuristieken worden ge\"implementeerd als een evoluerende populatie (mogelijk bestaat de populatie uit \'e\'en individu) met transitiefuncties. De reden is dat men verwacht dat men iets uit het verleden kan leren en goede oplossingen meestal minimaal van elkaar verschillen (dit kan beargumenteerd worden met een studie in \cite{kirkPatrick}). Indien we aan deze assumptie geen geloof hechten kunnen we op een andere manier de optimale oplossing proberen te vinden. Vermits de variabelen en de bijbehorende domeinen op voorhand gekend zijn, kan een programma een toevallige oplossing genereren. Bovendien kunnen we een programma zo ontwerpen dat het uitsluitend oplossingen genereert die nog niet eerder gegenereerd werden in dit in een tijdscomplexiteit onafhankelijk van het aantal eerder gegenereerde oplossingen.
\paragraph{}
Stel dat het domein exact \'e\'en optimale oplossing bevat, dan is de kans dat we in iteratie $t$ deze waarde vinden gelijk aan:
\begin{equation}
\Prob{\theta=t|\theta\geq t}=\guards{
0&\mbox{if }t>N\\
1/N-t+1&\mbox{otherwise}
}
\end{equation}
Met $N$ het aantal mogelijke configuraties ($N=\bigoh{\prod_i\abs{A_i}}$). In dat geval is gemiddelde raaktijd:
\begin{equation}
\mean{\hittime}=\displaystyle\sum_{i=1}^N\Prob{\hittime\geq i}=\displaystyle\sum_{i=1}^N\displaystyle\frac{i}{N}=\displaystyle\frac{N+1}{2}
\end{equation}
In het geval dat we dit algoritme op $p$ machines laten draaien bekomen we:
\begin{equation}
\mean{\phittime}=\displaystyle\sum_{i=1}^N\Prob{\phittime\geq i}=\displaystyle\sum_{i=1}^N\Prob{\hittime\geq i}^p=\displaystyle\frac{1}{N^p}\displaystyle\sum_{i=1}^Ni^p\approx\displaystyle\frac{N}{p+1}
\end{equation}
De laatste benadering bekomen we omdat de som een veelterm van graad $p+1$ is met $1/p+1$ als leidende co\"effici\"ent. Bijgevolg is de \emph{speed-up} bij benadering gelijk aan:
\begin{equation}
\mbox{speed-up}=\displaystyle\frac{\mean{\hittime}}{\mean{\phittime}}\approx\displaystyle\frac{\brak{N+1}\cdot\brak{p+1}}{2\cdot N}\approx\displaystyle\frac{p+1}{2}
\eqnlab{minimalSpeedupMetaheuristic}
\end{equation}
De formule is verder te veralgemenen naar $g$ gewenste oplossingen maar leidt tot dezelfde speed-up. Men dient wel op te merken dat er doorgaans betere algoritmen bestaan om naar de oplossing te zoeken dan louter per toeval configuraties te genereren en in dat geval is het meestal minder evident om dezelfde speed-up te realiseren.



\subsection{Parallelliseren van metaheuristieken in de praktijk}

Een referentiewerk hoe men metaheuristieken in de praktijk op verschillende processoren laat werken is ``\emph{Parallel Metaheuristics: A New Class of Algorithms}'' van Alba\cite{Alba2005book}. In het boek maakt men het eerder vermelde onderscheid tussen \emph{Local Search Metaheuristics (LMS)} en anderzijds \emph{Evolutionary Algorithms (EA)}.
\paragraph{}
Bij de \emph{Local Search Metaheuristics} ziet men drie bronnen tot parallellisme:
\begin{enumerate}
 \item \emph{Parallel multistart}: de processoren starten met een verschillende initi\"ele populatie en werken min of meer onafhankelijk. Dit is het parallellisatie-paradigma die we in de modellering hebben beschouwd.
 \item \emph{Parallel moves}: we beschouwen \'e\'en globale actieve oplossing. Wanneer we een migratie uitvoeren op een sequenti\"ele implementatie genereren we echter \'e\'en oplossing. We kunnen elke processor een migratie laten uitvoeren en vervolgens uit de verzameling van oplossingen uit de omgeving een nieuwe actieve oplossing kiezen. In het geval we een \emph{Local Search} stap uitvoeren kunnen we bijvoorbeeld ook elke processor een deel van de volledige omgeving laten afzoeken.
 \item \emph{Move acceleration}: een migratie kan er soms uit bestaan dat een significant deel van de oplossing verandert. Bovendien kan de evaluatiefunctie zelf ook moeilijk uit te rekenen zijn. Bij \emph{move acceleration} zijn we in staat om de oplossing op te delen in min of meer onafhankelijke delen. Elke processor past een deel van de configuratie aan en rekent de verandering van fitness-waarde met betrekking tot dit deel uit. Soms is er nog postprocessing vereist om de uiteindelijke fitness-waarde te berekenen. In andere modellen laat men fouten toe in de evaluatiefunctie en berekend men de fitness-waarde maar sporadisch correct.
\end{enumerate}

\paragraph{}
In het geval van \emph{Evolutionary Algorithms} ziet men drie bronnen tot parallellisme:
\begin{enumerate}
 \item \emph{Parallel computation}: meestal dient men operaties toe te passen op een significant deel van de populatie (bijvoorbeeld het berekenen van fitness-waardes). Vermits oplossingen nog steeds onafhankelijke entiteiten zijn, is dit een inherente vorm van parallellisatie.
 \item \emph{Parallel population}: men kan ook op elke processor en onafhankelijke populatie beschouwen waarop de processor dan werkt. Meestal gaat dit enigszins gepaard met kruisbestuiving: het uitwisselen van sterke oplossingen. Meestal noemt een genetisch algoritme waarbij men subpopulaties beschouwd een \emph{Island Model}\cite{islandModel}.
\end{enumerate}

\paragraph{}
In de bovenstaande modellen tot parallellisatie zijn de bronnen geordend in stijgende granulariteit. Meestal introduceert een fijnere granulariteit echter ook problemen in verband met mogelijke speed-ups: na elke stap worden de processoren opnieuw gesynchroniseerd. Op het moment dat een processor klaar is met zijn werk dient er gewacht te worden tot ook andere processoren deze \emph{barrier} bereiken. Dit introduceert dan ook een vorm van overhead. \cite{conf/glvlsi/HaldarNCB00} rapporteert bijvoorbeeld een negatieve speed-up door het grote aantal synchronisatiestappen.

\paragraph{}
Crainic en Toulouse\cite{crainicAndToulouse} delen de parallellisatie van metaheuristieken op in drie algemene types. Onder \emph{Type 1} vallen de \emph{Move acceleration}, \emph{Parallel moves} en \emph{Parallel computation} paradigma's van Alba. \cite{crainicAndToulouse} stellen dat dit type van parallellisatie uitsluitend probeert om operaties of evaluaties te versnellen. Wanneer men echter het algoritme op een sequenti\"ele processor draait met eenzelfde aantal iteraties, verwachten we dat dezelfde elementen in de oplossingsruimte werden onderzocht. \emph{Type 3} komt overeen met \emph{Parallel multistart} en \emph{Parallel population}. Crainic en Toulouse argumenteren hier dat al deze technieken leiden tot parallelle verkenning van dezelfde zoekruimte. \emph{Type 2} is een vorm van parallellisme die in Alba minder aan bod komt: het opdelen van de zoekruimte. Dit gebeurt door een deel van de variabelen vaste waardes te laten aannemen, de overige variabelen worden dan geoptimaliseerd door de verschillende processoren. Meestal kiest men per processor andere variabelen. Op vaste tijdstippen zal een processor vervolgens de configuraties van de verschillende processoren samenvoegen in \'e\'en globale oplossing. Omdat dit systeem sommige delen van de configuratieruimte onbezocht kan laten worden op geregelde tijdstippen nieuwe oplossingsruimtes aan de processoren toegekend.

\paragraph{}
Crainic en Toulouse maken ook een onderscheid in \emph{type 3} tussen \emph{interagerende processen} en \emph{niet-interagerende processen}. In het tweede geval wisselen de processen ook bepaalde aspecten in het zoekproces. Men verwacht dat met behulp van deze informatie er betere strategie\"en kunnen worden ontwikkeld die een metaheuristiek sneller naar de oplossing zullen leiden.

\subsubsection{Empirische resultaten}

Alba geeft in zijn boek een uitgebreid overzicht over verschillende pogingen om metaheuristieken te parallelliseren. In een groot aantal families van metaheuristieken is lineaire speed-up geen evidentie. In het geval van \emph{Ant Colony Optimisation (ACO)} bijvoorbeeld rapporteren zowel \cite{alba8-42,alba8-38,alba8-7,alba8-16} lage effici\"entie (meestal rond de 0.40) die meestal daalt naarmate het aantal processoren toeneemt. Andere paradigma's, zoals bijvoorbeeld \emph{Tabu Search}, halen wel sterke resultaten die meestal lineaire speed-up benaderen.

\subsubsection{Speed-up als een goede metriek?}
Empirische resultaten tonen dat de empirische speed-up sterk kan vari\"eren naargelang het paradigma van de metaheuristiek. Ook wanneer men een sterke \emph{speed-up} realiseert, ontbreken harde garanties dat dit op alle probleeminstanties het geval zal zijn. \cite{crainicAndToulouse} plaats daarom vraagtekens bij de betekenis van \emph{speed-up}. Omdat we meestal de exacte oplossing niet kennen is speed-up bovendien moeilijk te verifi\"eren: een parallel algoritme kan snel sterke oplossingen genereren, maar zal misschien niet significant sneller de echte oplossing vinden. Bovendien zal men meestal de uitvoer stopzetten alvorens een metaheuristiek de oplossing heeft gevonden. \cite{crainicAndToulouse} stelt daarom drie andere metrieken voor: kwalitatief sterkere oplossingen gedurende een significant deel van het zoekproces, robuustere systemen die meer garantie bieden op een sterke oplossing, of een algoritme die de algemene tijdscomplexiteit naar omlaag haalt.

\subsubsection{Parallellisatie met behulp van aangepast hardware}
Het boek besteed ook aandacht aan hardware-parallellisatie: simulaties tonen aan dat een processor soms een significante hoeveelheid rekentijd besteed aan communicatie met andere processoren. Door hardware te ontwikkelen kan men de rekentijd verder beperken. Sommige metaheuristieken zijn bijvoorbeeld op een \emph{Field Programmable Gate Array (FPGA)} ge\"implementeerd\cite{conf/glvlsi/HaldarNCB00,conf/fpt/GuntschMSDESS02,journals/gpem/Martin01}.

\section{Hyperheuristieken}

Deze masterthesis behandelt het parallelliseren van hyperheuristieken. Hyperheuristieken zijn een veralgemening van metaheuristieken. In \algref{metaheuristicGeneral} genereert het algoritme een nieuwe populatie uit de vorige populatie. Hoe dit concreet gebeurt is de verantwoordelijkheid van de metaheuristiek. Een hyperheuristiek gaat in de eerste plaats op zoek naar een sterke oplossingsmethode, niet een sterke oplossing\cite{Burke_aclassification}.
\begin{definition}[Hyperheuristiek\cite{Burke_aclassification}]
Een hyperheuristiek is een automatische methodologie voor het selecteren of genereren van heuristieken om moeilijke computationele zoekproblemen op te lossen.
\end{definition}

\paragraph{}
De definitie zelf maakt hierbij al een onderscheid tussen twee mechanismes\cite{Burke_aclassification}:
\begin{enumerate}
 \item \emph{Heuristic selection}: de hyperheuristiek kiest een transitiefunctie die wordt toegepast op de populatie.
 \item \emph{Heuristic generation}: de hyperheuristiek ontwikkelt zelf transitiefuncties op basis van aangereikte componenten.
\end{enumerate}

Het selecteren of genereren van een hyperheuristiek kan op verschillende manieren gebeuren. Men maakt meestal een onderscheid tussen \emph{no-learning}, \emph{offline learning} en \emph{online learning}.

\subsection{Motivatie}
Meestal gebruikt men hyperheuristieken in het geval het probleem complex is en men dus geen metaheuristiek kan voorstellen die het probleem effectief oplost. Meestal is dit het geval bij problemen waar de instanties heel divers kunnen zijn, en men in het ontwerp van de metaheuristiek er niet in slaagt alle families van probleeminstanties te beschouwen.
\paragraph{}
Hyperheuristieken kunnen ook ingezet worden bij de ontwikkeling van een mechanisme die verschillende problemen kan oplossen. De set van transitiefuncties (of componenten) maakt immers deel uit van de invoer. Door andere functies in te voeren kan men andere problemen oplossen. Hyperheuristieken worden daarom vaak voorgesteld als een oplossingstechniek die er op termijn moet in slagen alle optimalisatieproblemen benaderend op te lossen.

\subsection{Het effect van de transitiefuncties}
\cite{misirEffect} onderzoekt in welke mate het invoeren van andere transitiefuncties tot andere resultaten leidt. In plaats van totaal verschillende transitiefuncties in te voeren werden er echter varianten op bestaande transitiefuncties gebruikt waarbij de onderliggende transitiefunctie simpelweg een aantal keer werd herhaald. Dit leidt er dus toe dat de omgeving van een transitiefunctie sterker wordt.
\paragraph{}
Vermits de achterliggende transitiefuncties echter dezelfde waren, verwachtte men dat hyperheuristieken die in de studie werden onderzocht verhoudingsgewijs even sterk zouden scoren. Dit bleek echter niet het geval te zijn. Hyperheuristiek die minder sterk scoorden op de orginele transitiefuncties, scoorden soms beter op de afgeleide heuristieken. Dit resultaat Vormt een indicatie dat de huidige hyperheuristieken momenteel onvoldoende leren de effecten van de onderliggende heuristieken kunnen begrijpen.

\subsection{Parallelle Hyperheuristieken}

Hyperheuristieken zijn meestal minder effici\"ent voor specifieke optimalisatieproblemen waarvoor sterke metaheuristieken bestaan. De rede is dat eerst de sterktes en zwaktes van de verschillende heuristieken moeten worden geleerd. Vermits de heuristieken bovendien in eender welke sequentie kunnen voorkomen, kan men geen specifieke optimalisaties doorvoeren. In deze context kan het nuttig zijn om een hyperheuristiek op verschillende processoren te laten werken.

\paragraph{}
Het idee is niet nieuw en werd reeds op enkele problemen toegepast. \cite{conf/gecco/LeonMS08,conf/pdp/SeguraSL12} ontwikkelden een systeem gebaseerd op genetische algoritmen. Een genetisch algoritme wordt onderverdeeld in enkele componenten. Een \emph{master} stuurt bepaald welke de componenten die een \emph{worker} vervolgens gebruikt om lokaal een genetisch algoritme te laten werken. Wanneer een stopcriterium is bereikt, worden de resultaten doorgestuurd en zal de \emph{master} de \emph{worker} een nieuwe set componenten geven. In \cite{conf/pdp/SeguraSL12} voert men een studie uit op het adaptief vermogen van dit systeem. Er wordt aangetoond dat het systeem snel meer dan de helft van de beschikbare rekenkracht aan de sterkste genetische configuratie geeft. Het systeem maakt echter gebruik van een parameter en de robuustheid is nog niet aangetoond. Wanneer men met dit systeem het \prbm{Antenna Positioning Problem (APP)} oplost, stelt men vast dat de verbetering stagneert naarmate men het aantal processoren opdrijft. Bovendien boekt men op middellange termijn meestal slechtere prestaties met meerdere processoren.

\paragraph{}
Planningsproblemen werden opgelost met behulp van parallelle hyperheuristieken in \cite{Rattadilok04adistributed}. Men laat heuristieken uitvoeren op oplossingen door verschillende processoren. Deze processoren worden aangestuurd door een \emph{controller}. Verschillende \emph{controller}s communiceren met elkaar om ervaring uit te wisselen. Een probleem met deze benadering is dat de \emph{controller} zelf op een processor draait en meestal amper data verwerkt en bijgevolg ineffici\"ent omspringt met de aangeboden rekenkracht. Men stelt een consistente \emph{speed-up} vast maar de effici\"entie daalt naarmate het aantal processoren stijgt. Bovendien zijn de oplossing niet altijd kwalitatief beter.

\paragraph{}
\emph{Multiobjectivisation} -- het omzetten van \'e\'en evaluatiefunctie in verschillende evaluatiefuncties -- is de drijvende kracht in \cite{Luna08usinga}. Doordat elke processor een andere functie probeert te optimaliseren hoopt men tot een meer robuuste oplossingsmethode te komen.


\section{Besluit van dit hoofdstuk}
Optimalisatieproblemen die een grote zoekruimte omvatten kunnen doorgaans niet exact opgelost worden. Meestal maken we daarom gebruik van een heuristiek: een methode die een benaderende oplossing voorstelt.

\paragraph{}
Een metaheuristiek is een verzamelnaam voor een diverse groep algoritmen die voor een gegeven optimalisatieprobleem een aanvaardbare oplossing proberen uit te rekenen. Al deze methodes werken in grote mate met toevalsgetallen.

\paragraph{}
De meeste metaheuristieken omvatten verschillende bronnen om het algoritme parallel uit te voeren. \cite{DBLP:journals/jc/ShonkwilerV94} beschrijft een model die aantoont dat wanneer men onafhankelijke metaheuristieken op verschillende processoren laat lopen, men soms lineaire \emph{speed-up} kan benaderen. De concrete speed-up hangt af van het probleem en de oplossingsmethode.

\paragraph{}
\cite{Alba2005book} is een naslagwerk die verschillende parallelle implementaties van metaheuristieken groepeert. Men kan vaststellen dat de \emph{speed-up} eerder wisselvallig is. In sommige gevallen is er zelfs sprake van negatieve \emph{speed-up} door een hoge communicatie-kost.

\paragraph{}
Hyperheuristieken proberen een oplossingsmethode aan te reiken die minder afhankelijk is van een concreet probleem. Dit doet men door een algoritme een keuze te laten maken uit een set transitiefuncties een gaandeweg de sterktes en zwaktes van de concrete transitiefuncties te laten kennen.

\paragraph{}
Er bestaan reeds implementaties van parallelle hyperheuristieken. Deze algoritmen werken meestal in een \emph{master-slave} verhouding waar de \emph{master} zich voornamelijk bezighoudt met de selectie van de heuristieken en het \emph{slave}-gedeelte de heuristieken uitvoert. Soms is er sprake van meerdere \emph{master}-componenten die informatie met elkaar uitwisselen.

\paragraph{}
Een andere techniek die gebruikt wordt is \emph{multiobjectivisation}: het opsplitsen van de evaluatiefunctie in verschillende functies zodat elke processor een aangepast optimalisatieprobleem uitvoert.

\paragraph{}
De huidige prestaties van parallelle hyperheuristieken zijn eerder wisselvallig en hangen vaak af van het probleem in kwestie.

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "masterproef"
%%% End:
